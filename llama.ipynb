{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.54.4)\n",
      "Requirement already satisfied: nltk in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: yake in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.4.8)\n",
      "Requirement already satisfied: textgrad in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.1.5)\n",
      "Requirement already satisfied: rouge-score in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tabulate in /usr/local/python/3.12.1/lib/python3.12/site-packages (from yake) (0.9.0)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from yake) (2.1.2)\n",
      "Requirement already satisfied: segtok in /usr/local/python/3.12.1/lib/python3.12/site-packages (from yake) (1.5.11)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from yake) (3.2.1)\n",
      "Requirement already satisfied: jellyfish in /usr/local/python/3.12.1/lib/python3.12/site-packages (from yake) (1.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from textgrad) (9.0.0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from textgrad) (1.0.1)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from textgrad) (2.2.2)\n",
      "Requirement already satisfied: platformdirs>=3.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from textgrad) (4.3.6)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from textgrad) (3.1.0)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from textgrad) (5.6.3)\n",
      "Requirement already satisfied: graphviz>=0.20.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from textgrad) (0.20.3)\n",
      "Requirement already satisfied: gdown>=5.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from textgrad) (5.2.0)\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (from textgrad) (11.0.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/codespace/.local/lib/python3.12/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.14.6->textgrad) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (3.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (0.26.2)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.14.6->textgrad) (6.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/codespace/.local/lib/python3.12/site-packages (from gdown>=5.2.0->textgrad) (4.12.3)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.5.3->textgrad) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.14.6->textgrad) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp->datasets>=2.14.6->textgrad) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.14.6->textgrad) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.14.6->textgrad) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (2.2.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4->gdown>=5.2.0->textgrad) (2.6)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from requests[socks]->gdown>=5.2.0->textgrad) (1.7.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai nltk yake textgrad rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "Processing 200 samples:\n",
      "Start time: 2024-11-16 17:05:18\n",
      "Estimated completion: 2024-11-16 17:21:18\n",
      "Estimated duration: 0:16:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples:   0%|          | 0/200 [00:00<?, ?it/s]2024-11-16 17:05:22,640 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:22,642 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:22,643 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:22,644 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:22,645 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:22,645 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:22,646 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:22,652 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:22,725 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:22,818 - INFO - Progress: 3 samples processed in 0:00:04.200147\n",
      "2024-11-16 17:05:22,819 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing samples:   0%|          | 1/200 [00:04<13:52,  4.18s/it]2024-11-16 17:05:22,822 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:22,823 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:22,824 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:22,824 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:22,826 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:22,826 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:22,833 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:22,895 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:22,897 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:22,898 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:22,899 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:22,899 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:22,901 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:22,901 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:22,907 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:22,966 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:23,007 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:23,012 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:23,015 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:23,016 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:23,018 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:23,019 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:23,020 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:23,021 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:23,027 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:23,158 - INFO - Progress: 4 samples processed in 0:00:04.540350\n",
      "Processing samples:   1%|          | 2/200 [00:04<06:20,  1.92s/it]2024-11-16 17:05:23,228 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:23,298 - INFO - Progress: 1 samples processed in 0:00:04.680291\n",
      "Processing samples:   2%|▏         | 3/200 [00:04<03:38,  1.11s/it]2024-11-16 17:05:23,371 - INFO - Progress: 2 samples processed in 0:00:04.753310\n",
      "2024-11-16 17:05:27,049 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:27,153 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:27,155 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:27,155 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:27,156 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:27,157 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:27,187 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:27,189 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:27,190 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:27,465 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:27,467 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:27,467 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:27,468 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:27,469 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:27,470 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:27,470 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:27,476 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:27,574 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:27,647 - INFO - Progress: 7 samples processed in 0:00:09.029272\n",
      "Processing samples:   2%|▎         | 5/200 [00:09<05:33,  1.71s/it]2024-11-16 17:05:28,241 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:28,243 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:28,243 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:28,248 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:28,317 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:28,386 - INFO - Progress: 8 samples processed in 0:00:09.767496\n",
      "Processing samples:   3%|▎         | 6/200 [00:09<04:37,  1.43s/it]2024-11-16 17:05:29,543 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:29,545 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:29,546 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:30,225 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:30,227 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:30,228 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:31,696 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:31,698 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:31,698 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:31,704 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:31,792 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:31,827 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:31,829 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:31,830 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:31,831 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:31,832 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:31,833 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:31,834 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:31,842 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:31,885 - INFO - Progress: 6 samples processed in 0:00:13.267133\n",
      "Processing samples:   4%|▎         | 7/200 [00:13<06:32,  2.03s/it]2024-11-16 17:05:31,979 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:32,064 - INFO - Progress: 9 samples processed in 0:00:13.445849\n",
      "Processing samples:   4%|▍         | 8/200 [00:13<04:45,  1.49s/it]2024-11-16 17:05:32,753 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:32,755 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:32,756 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:33,347 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:33,350 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:33,350 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:33,351 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:33,352 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:33,353 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:33,353 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:33,359 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:33,458 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:33,521 - INFO - Progress: 10 samples processed in 0:00:14.903414\n",
      "Processing samples:   4%|▍         | 9/200 [00:14<04:42,  1.48s/it]2024-11-16 17:05:34,408 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:34,410 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:34,411 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:34,417 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:34,489 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:34,577 - INFO - Progress: 5 samples processed in 0:00:15.958834\n",
      "Processing samples:   5%|▌         | 10/200 [00:15<04:17,  1.35s/it]2024-11-16 17:05:38,189 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:38,406 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:38,417 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:40,286 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:42,969 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:42,970 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:42,971 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:43,025 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:43,027 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:43,028 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:43,321 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:43,323 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:43,323 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:43,800 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:43,803 - INFO - LLMCall function forward\n",
      "2024-11-16 17:05:43,803 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:05:48,144 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:48,146 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:48,146 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:48,202 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:48,204 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:48,205 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:48,258 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:48,271 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:48,272 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:48,441 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:48,444 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:05:48,444 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:05:50,350 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:50,352 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:50,353 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:50,359 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:50,431 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:50,432 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:50,439 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:50,440 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:50,445 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:50,552 - INFO - Progress: 13 samples processed in 0:00:31.934033\n",
      "Processing samples:   6%|▌         | 11/200 [00:31<17:59,  5.71s/it]2024-11-16 17:05:50,588 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:50,657 - INFO - Progress: 11 samples processed in 0:00:32.038857\n",
      "Processing samples:   6%|▌         | 12/200 [00:32<12:38,  4.04s/it]2024-11-16 17:05:50,791 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:50,792 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:50,793 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:50,795 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:50,802 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:50,819 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:05:50,819 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:05:50,826 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:50,951 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:50,999 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:05:51,114 - INFO - Progress: 12 samples processed in 0:00:32.496435\n",
      "Processing samples:   6%|▋         | 13/200 [00:32<09:14,  2.97s/it]2024-11-16 17:05:51,181 - INFO - Progress: 14 samples processed in 0:00:32.563309\n",
      "2024-11-16 17:05:55,764 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:55,904 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:56,286 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:57,229 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:05:57,230 - INFO - Retrying request to /chat/completions in 0.486997 seconds\n",
      "2024-11-16 17:05:58,028 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:05:58,029 - INFO - Retrying request to /chat/completions in 0.813650 seconds\n",
      "2024-11-16 17:05:58,459 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:05:58,760 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:05:58,761 - INFO - Retrying request to /chat/completions in 0.378517 seconds\n",
      "2024-11-16 17:05:59,160 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:00,041 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:00,042 - INFO - Retrying request to /chat/completions in 0.983890 seconds\n",
      "2024-11-16 17:06:00,432 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:00,433 - INFO - Retrying request to /chat/completions in 0.447407 seconds\n",
      "2024-11-16 17:06:01,006 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:01,008 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:01,008 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:01,224 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:01,225 - INFO - Retrying request to /chat/completions in 0.919420 seconds\n",
      "2024-11-16 17:06:01,268 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:01,268 - INFO - Retrying request to /chat/completions in 0.486922 seconds\n",
      "2024-11-16 17:06:01,272 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:01,274 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:01,275 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:01,276 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:01,548 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:01,549 - INFO - Retrying request to /chat/completions in 0.439976 seconds\n",
      "2024-11-16 17:06:02,043 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:02,043 - INFO - Retrying request to /chat/completions in 0.766802 seconds\n",
      "2024-11-16 17:06:02,279 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:02,280 - INFO - Retrying request to /chat/completions in 0.820730 seconds\n",
      "2024-11-16 17:06:02,418 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:02,542 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:02,543 - INFO - Retrying request to /chat/completions in 0.410477 seconds\n",
      "2024-11-16 17:06:03,129 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:03,438 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:03,439 - INFO - Retrying request to /chat/completions in 0.759816 seconds\n",
      "2024-11-16 17:06:03,473 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:04,037 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:04,038 - INFO - Retrying request to /chat/completions in 0.431638 seconds\n",
      "2024-11-16 17:06:04,471 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:04,557 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:04,558 - INFO - Retrying request to /chat/completions in 0.495176 seconds\n",
      "2024-11-16 17:06:04,769 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:04,770 - INFO - Retrying request to /chat/completions in 0.974056 seconds\n",
      "2024-11-16 17:06:04,818 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:04,819 - INFO - Retrying request to /chat/completions in 0.418273 seconds\n",
      "2024-11-16 17:06:05,307 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:05,308 - INFO - Retrying request to /chat/completions in 0.779294 seconds\n",
      "2024-11-16 17:06:05,576 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:05,577 - INFO - Retrying request to /chat/completions in 0.776510 seconds\n",
      "2024-11-16 17:06:06,008 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:06,371 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:06,631 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:06,717 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:06,718 - INFO - Retrying request to /chat/completions in 0.459762 seconds\n",
      "2024-11-16 17:06:07,525 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:07,525 - INFO - Retrying request to /chat/completions in 0.402014 seconds\n",
      "2024-11-16 17:06:07,555 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:07,555 - INFO - Retrying request to /chat/completions in 0.944141 seconds\n",
      "2024-11-16 17:06:07,971 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:07,971 - INFO - Retrying request to /chat/completions in 0.434175 seconds\n",
      "2024-11-16 17:06:08,031 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:08,032 - INFO - Retrying request to /chat/completions in 0.480198 seconds\n",
      "2024-11-16 17:06:08,199 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:08,200 - INFO - Retrying request to /chat/completions in 0.782436 seconds\n",
      "2024-11-16 17:06:08,662 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:08,663 - INFO - Retrying request to /chat/completions in 0.957258 seconds\n",
      "2024-11-16 17:06:08,763 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:08,764 - INFO - Retrying request to /chat/completions in 0.959607 seconds\n",
      "2024-11-16 17:06:08,783 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:09,262 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:09,903 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:09,981 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:11,229 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:11,229 - INFO - Retrying request to /chat/completions in 0.405069 seconds\n",
      "2024-11-16 17:06:11,410 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:11,411 - INFO - Retrying request to /chat/completions in 0.446615 seconds\n",
      "2024-11-16 17:06:11,905 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:11,906 - INFO - Retrying request to /chat/completions in 0.906339 seconds\n",
      "2024-11-16 17:06:12,011 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:12,012 - INFO - Retrying request to /chat/completions in 0.460657 seconds\n",
      "2024-11-16 17:06:12,142 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:12,143 - INFO - Retrying request to /chat/completions in 0.903079 seconds\n",
      "2024-11-16 17:06:12,723 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:12,724 - INFO - Retrying request to /chat/completions in 0.995765 seconds\n",
      "2024-11-16 17:06:13,098 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:13,099 - INFO - Retrying request to /chat/completions in 0.439123 seconds\n",
      "2024-11-16 17:06:13,145 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:13,315 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:13,786 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:13,786 - INFO - Retrying request to /chat/completions in 0.854272 seconds\n",
      "2024-11-16 17:06:14,014 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:14,892 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:14,893 - ERROR - Error processing index 15: RetryError[<Future at 0x73f519a81970 state=finished raised RateLimitError>]\n",
      "Processing samples:   8%|▊         | 15/200 [00:56<21:49,  7.08s/it]2024-11-16 17:06:15,785 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:15,786 - INFO - Retrying request to /chat/completions in 0.378989 seconds\n",
      "2024-11-16 17:06:16,250 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:16,251 - INFO - Retrying request to /chat/completions in 0.470548 seconds\n",
      "2024-11-16 17:06:16,421 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:16,422 - INFO - Retrying request to /chat/completions in 0.893003 seconds\n",
      "2024-11-16 17:06:16,791 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:16,792 - INFO - Retrying request to /chat/completions in 0.408639 seconds\n",
      "2024-11-16 17:06:16,973 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:16,974 - INFO - Retrying request to /chat/completions in 0.798185 seconds\n",
      "2024-11-16 17:06:17,523 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:17,523 - INFO - Retrying request to /chat/completions in 0.968227 seconds\n",
      "2024-11-16 17:06:17,566 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:17,567 - ERROR - Error processing index 16: RetryError[<Future at 0x73f519add160 state=finished raised RateLimitError>]\n",
      "Processing samples:   8%|▊         | 16/200 [00:58<18:21,  5.99s/it]2024-11-16 17:06:18,040 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:18,042 - ERROR - Error processing index 17: RetryError[<Future at 0x73f545df2d50 state=finished raised RateLimitError>]\n",
      "Processing samples:   8%|▊         | 17/200 [00:59<13:52,  4.55s/it]2024-11-16 17:06:18,775 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:18,777 - ERROR - Error processing index 14: RetryError[<Future at 0x73f519a38e60 state=finished raised RateLimitError>]\n",
      "Processing samples:   9%|▉         | 18/200 [01:00<10:38,  3.51s/it]2024-11-16 17:06:19,819 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:20,872 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:20,873 - INFO - Retrying request to /chat/completions in 0.453562 seconds\n",
      "2024-11-16 17:06:21,653 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:21,654 - INFO - Retrying request to /chat/completions in 0.955972 seconds\n",
      "2024-11-16 17:06:21,786 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:21,918 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:22,443 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:23,688 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:23,690 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:23,691 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:24,803 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:24,805 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:24,805 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:24,881 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:24,883 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:24,884 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:25,129 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:25,131 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:25,131 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:25,431 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:25,433 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:06:25,433 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:06:26,503 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:26,505 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:06:26,505 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:06:26,622 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:26,624 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:06:26,624 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:06:26,632 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:26,677 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:26,679 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:06:26,680 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:06:26,727 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:26,813 - INFO - Progress: 20 samples processed in 0:01:08.194937\n",
      "Processing samples:  10%|▉         | 19/200 [01:08<14:24,  4.78s/it]2024-11-16 17:06:27,012 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:27,014 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:06:27,015 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:06:27,359 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:27,361 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:06:27,362 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:06:27,368 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:27,455 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:27,539 - INFO - Progress: 21 samples processed in 0:01:08.920679\n",
      "Processing samples:  10%|█         | 20/200 [01:08<10:51,  3.62s/it]2024-11-16 17:06:27,987 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:27,989 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:06:27,989 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:06:27,994 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:28,037 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:28,098 - INFO - Progress: 22 samples processed in 0:01:09.480059\n",
      "Processing samples:  10%|█         | 21/200 [01:09<08:09,  2.73s/it]2024-11-16 17:06:28,747 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:28,750 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:06:28,750 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:06:28,757 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:28,840 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:06:28,912 - INFO - Progress: 19 samples processed in 0:01:10.294137\n",
      "Processing samples:  11%|█         | 22/200 [01:10<06:26,  2.17s/it]2024-11-16 17:06:31,436 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:32,191 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:33,086 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:33,312 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:33,500 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:33,501 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:33,502 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:34,418 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:34,420 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:34,421 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:34,823 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:34,825 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:34,826 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:35,061 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:35,063 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:06:35,064 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:06:35,106 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:35,106 - INFO - Retrying request to /chat/completions in 0.421713 seconds\n",
      "2024-11-16 17:06:35,122 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:35,124 - INFO - LLMCall function forward\n",
      "2024-11-16 17:06:35,124 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:06:35,332 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:35,333 - INFO - Retrying request to /chat/completions in 0.467432 seconds\n",
      "2024-11-16 17:06:35,394 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:35,395 - INFO - Retrying request to /chat/completions in 0.400739 seconds\n",
      "2024-11-16 17:06:35,774 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:35,775 - INFO - Retrying request to /chat/completions in 0.997858 seconds\n",
      "2024-11-16 17:06:36,044 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:36,045 - INFO - Retrying request to /chat/completions in 0.771296 seconds\n",
      "2024-11-16 17:06:36,049 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:36,049 - INFO - Retrying request to /chat/completions in 0.935670 seconds\n",
      "2024-11-16 17:06:36,239 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:36,241 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:06:36,242 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:06:36,541 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:36,542 - INFO - Retrying request to /chat/completions in 0.403337 seconds\n",
      "2024-11-16 17:06:37,032 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:37,061 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:37,237 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:37,238 - INFO - Retrying request to /chat/completions in 0.826410 seconds\n",
      "2024-11-16 17:06:37,291 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:38,341 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:38,341 - INFO - Retrying request to /chat/completions in 0.486659 seconds\n",
      "2024-11-16 17:06:38,358 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:38,358 - INFO - Retrying request to /chat/completions in 0.477381 seconds\n",
      "2024-11-16 17:06:38,360 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:38,563 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:38,564 - INFO - Retrying request to /chat/completions in 0.464370 seconds\n",
      "2024-11-16 17:06:39,081 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:39,082 - INFO - Retrying request to /chat/completions in 0.786922 seconds\n",
      "2024-11-16 17:06:39,089 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:39,090 - INFO - Retrying request to /chat/completions in 0.848265 seconds\n",
      "2024-11-16 17:06:39,329 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:39,331 - INFO - Retrying request to /chat/completions in 0.761071 seconds\n",
      "2024-11-16 17:06:39,661 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:39,661 - INFO - Retrying request to /chat/completions in 0.474911 seconds\n",
      "2024-11-16 17:06:40,146 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:40,214 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:40,366 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:40,409 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:40,410 - INFO - Retrying request to /chat/completions in 0.830776 seconds\n",
      "2024-11-16 17:06:41,500 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:41,837 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:41,838 - INFO - Retrying request to /chat/completions in 0.405744 seconds\n",
      "2024-11-16 17:06:41,937 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:41,938 - INFO - Retrying request to /chat/completions in 0.398706 seconds\n",
      "2024-11-16 17:06:42,494 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:42,495 - INFO - Retrying request to /chat/completions in 0.835599 seconds\n",
      "2024-11-16 17:06:42,560 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:42,560 - INFO - Retrying request to /chat/completions in 0.410199 seconds\n",
      "2024-11-16 17:06:42,610 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:42,611 - INFO - Retrying request to /chat/completions in 0.960030 seconds\n",
      "2024-11-16 17:06:42,825 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:42,826 - INFO - Retrying request to /chat/completions in 0.476065 seconds\n",
      "2024-11-16 17:06:43,291 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:43,292 - INFO - Retrying request to /chat/completions in 0.983065 seconds\n",
      "2024-11-16 17:06:43,586 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:43,596 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:43,596 - INFO - Retrying request to /chat/completions in 0.871172 seconds\n",
      "2024-11-16 17:06:43,960 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:44,543 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:44,731 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:46,654 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:46,655 - INFO - Retrying request to /chat/completions in 0.454480 seconds\n",
      "2024-11-16 17:06:47,296 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:47,297 - INFO - Retrying request to /chat/completions in 0.439580 seconds\n",
      "2024-11-16 17:06:47,360 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:47,360 - INFO - Retrying request to /chat/completions in 0.761572 seconds\n",
      "2024-11-16 17:06:47,838 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:47,839 - INFO - Retrying request to /chat/completions in 0.422660 seconds\n",
      "2024-11-16 17:06:48,001 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:48,002 - INFO - Retrying request to /chat/completions in 0.836968 seconds\n",
      "2024-11-16 17:06:48,271 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:48,271 - INFO - Retrying request to /chat/completions in 0.421664 seconds\n",
      "2024-11-16 17:06:48,382 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:48,618 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:48,619 - INFO - Retrying request to /chat/completions in 0.808492 seconds\n",
      "2024-11-16 17:06:48,943 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:48,944 - INFO - Retrying request to /chat/completions in 0.928235 seconds\n",
      "2024-11-16 17:06:49,265 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:49,789 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:50,178 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:51,577 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:51,578 - INFO - Retrying request to /chat/completions in 0.448091 seconds\n",
      "2024-11-16 17:06:52,281 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:52,281 - INFO - Retrying request to /chat/completions in 0.931044 seconds\n",
      "2024-11-16 17:06:52,883 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:52,883 - INFO - Retrying request to /chat/completions in 0.459887 seconds\n",
      "2024-11-16 17:06:53,482 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:53,484 - ERROR - Error processing index 22: RetryError[<Future at 0x73f5199f6060 state=finished raised RateLimitError>]\n",
      "Processing samples:  12%|█▏        | 23/200 [01:34<25:53,  8.78s/it]2024-11-16 17:06:53,636 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:53,637 - INFO - Retrying request to /chat/completions in 0.390985 seconds\n",
      "2024-11-16 17:06:53,714 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:53,715 - INFO - Retrying request to /chat/completions in 0.760178 seconds\n",
      "2024-11-16 17:06:54,304 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:54,305 - INFO - Retrying request to /chat/completions in 0.915228 seconds\n",
      "2024-11-16 17:06:54,362 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:54,363 - INFO - Retrying request to /chat/completions in 0.465972 seconds\n",
      "2024-11-16 17:06:54,734 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:54,735 - ERROR - Error processing index 23: RetryError[<Future at 0x73f5199a6150 state=finished raised RateLimitError>]\n",
      "Processing samples:  12%|█▏        | 24/200 [01:36<19:12,  6.55s/it]2024-11-16 17:06:55,115 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:55,116 - INFO - Retrying request to /chat/completions in 0.899925 seconds\n",
      "2024-11-16 17:06:55,516 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:55,517 - ERROR - Error processing index 25: RetryError[<Future at 0x73f544788170 state=finished raised RateLimitError>]\n",
      "Processing samples:  12%|█▎        | 25/200 [01:36<14:05,  4.83s/it]2024-11-16 17:06:56,265 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:56,267 - ERROR - Error processing index 24: RetryError[<Future at 0x73f51944c860 state=finished raised RateLimitError>]\n",
      "Processing samples:  13%|█▎        | 26/200 [01:37<10:28,  3.61s/it]2024-11-16 17:06:57,572 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:58,475 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:58,476 - INFO - Retrying request to /chat/completions in 0.488724 seconds\n",
      "2024-11-16 17:06:58,748 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:59,024 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:59,025 - INFO - Retrying request to /chat/completions in 0.426285 seconds\n",
      "2024-11-16 17:06:59,787 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:59,788 - INFO - Retrying request to /chat/completions in 0.788651 seconds\n",
      "2024-11-16 17:06:59,914 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:06:59,919 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:06:59,920 - INFO - Retrying request to /chat/completions in 0.920896 seconds\n",
      "2024-11-16 17:07:00,158 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:00,159 - INFO - Retrying request to /chat/completions in 0.416645 seconds\n",
      "2024-11-16 17:07:00,338 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:00,339 - INFO - Retrying request to /chat/completions in 0.455848 seconds\n",
      "2024-11-16 17:07:00,823 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:00,847 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:00,848 - INFO - Retrying request to /chat/completions in 0.768325 seconds\n",
      "2024-11-16 17:07:01,045 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:01,046 - INFO - Retrying request to /chat/completions in 0.850760 seconds\n",
      "2024-11-16 17:07:01,126 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:01,895 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:02,074 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:02,075 - INFO - Retrying request to /chat/completions in 0.430579 seconds\n",
      "2024-11-16 17:07:02,166 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:02,167 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:07:02,392 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:02,393 - INFO - Retrying request to /chat/completions in 0.467975 seconds\n",
      "2024-11-16 17:07:02,754 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:02,755 - INFO - Retrying request to /chat/completions in 0.969658 seconds\n",
      "2024-11-16 17:07:03,106 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:03,107 - INFO - Retrying request to /chat/completions in 0.925824 seconds\n",
      "2024-11-16 17:07:03,150 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:03,151 - INFO - Retrying request to /chat/completions in 0.391399 seconds\n",
      "2024-11-16 17:07:03,788 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:03,789 - INFO - Retrying request to /chat/completions in 0.789854 seconds\n",
      "2024-11-16 17:07:04,005 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:04,284 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:04,865 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:05,506 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:05,507 - INFO - Retrying request to /chat/completions in 0.493064 seconds\n",
      "2024-11-16 17:07:05,766 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:05,767 - INFO - Retrying request to /chat/completions in 0.472587 seconds\n",
      "2024-11-16 17:07:06,346 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:06,347 - INFO - Retrying request to /chat/completions in 0.834837 seconds\n",
      "2024-11-16 17:07:06,459 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:06,460 - INFO - Retrying request to /chat/completions in 0.459493 seconds\n",
      "2024-11-16 17:07:07,165 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:07,166 - INFO - Retrying request to /chat/completions in 0.852729 seconds\n",
      "2024-11-16 17:07:07,167 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:07,167 - INFO - Retrying request to /chat/completions in 0.913730 seconds\n",
      "2024-11-16 17:07:07,450 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:08,281 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:08,348 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:09,419 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:09,420 - INFO - Retrying request to /chat/completions in 0.456765 seconds\n",
      "2024-11-16 17:07:10,119 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:10,120 - INFO - Retrying request to /chat/completions in 0.908138 seconds\n",
      "2024-11-16 17:07:10,582 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:10,584 - INFO - Retrying request to /chat/completions in 0.460094 seconds\n",
      "2024-11-16 17:07:10,919 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:10,920 - INFO - Retrying request to /chat/completions in 0.416332 seconds\n",
      "2024-11-16 17:07:11,312 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:11,314 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:07:11,323 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:11,323 - INFO - Retrying request to /chat/completions in 0.834415 seconds\n",
      "2024-11-16 17:07:11,645 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:11,646 - INFO - Retrying request to /chat/completions in 0.993744 seconds\n",
      "2024-11-16 17:07:12,000 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:12,001 - INFO - Retrying request to /chat/completions in 0.486405 seconds\n",
      "2024-11-16 17:07:12,407 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:12,772 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:12,773 - INFO - Retrying request to /chat/completions in 0.867692 seconds\n",
      "2024-11-16 17:07:12,926 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:13,768 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:13,769 - INFO - Retrying request to /chat/completions in 0.461110 seconds\n",
      "2024-11-16 17:07:13,953 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:14,474 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:14,475 - INFO - Retrying request to /chat/completions in 0.768263 seconds\n",
      "2024-11-16 17:07:15,499 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:15,500 - ERROR - Error processing index 28: RetryError[<Future at 0x73f519987ef0 state=finished raised RateLimitError>]\n",
      "Processing samples:  14%|█▎        | 27/200 [01:56<23:52,  8.28s/it]2024-11-16 17:07:15,934 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:15,935 - INFO - Retrying request to /chat/completions in 0.446244 seconds\n",
      "2024-11-16 17:07:16,641 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:16,642 - INFO - Retrying request to /chat/completions in 0.971684 seconds\n",
      "2024-11-16 17:07:16,684 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:16,685 - INFO - Retrying request to /chat/completions in 0.491471 seconds\n",
      "2024-11-16 17:07:17,443 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:17,444 - INFO - Retrying request to /chat/completions in 0.955429 seconds\n",
      "2024-11-16 17:07:18,012 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:18,013 - ERROR - Error processing index 26: RetryError[<Future at 0x73f544760e00 state=finished raised RateLimitError>]\n",
      "Processing samples:  14%|█▍        | 28/200 [01:59<18:47,  6.56s/it]2024-11-16 17:07:18,584 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:18,585 - INFO - Retrying request to /chat/completions in 0.485724 seconds\n",
      "2024-11-16 17:07:18,666 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:18,667 - ERROR - Error processing index 27: RetryError[<Future at 0x73f5199a6f60 state=finished raised RateLimitError>]\n",
      "Processing samples:  14%|█▍        | 29/200 [02:00<13:38,  4.79s/it]2024-11-16 17:07:19,313 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:19,314 - INFO - Retrying request to /chat/completions in 0.814891 seconds\n",
      "2024-11-16 17:07:19,833 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:20,403 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:20,404 - WARNING - Attempt 3 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:07:20,404 - ERROR - All retry attempts failed for GPT response.\n",
      "2024-11-16 17:07:20,405 - ERROR - GPT response for index 29 is empty.\n",
      "Processing samples:  15%|█▌        | 30/200 [02:01<10:58,  3.87s/it]2024-11-16 17:07:22,148 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:22,149 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:22,152 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:22,155 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:22,699 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:24,698 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:25,205 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:25,207 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:25,207 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:25,223 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:25,225 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:25,226 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:25,458 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:25,460 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:25,461 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:26,279 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:26,281 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:26,281 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:26,288 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:26,397 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:26,465 - INFO - Progress: 31 samples processed in 0:02:07.847362\n",
      "Processing samples:  16%|█▌        | 31/200 [02:07<12:45,  4.53s/it]2024-11-16 17:07:26,657 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:26,659 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:26,660 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:26,858 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:26,860 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:26,861 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:27,294 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:27,296 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:27,296 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:29,503 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:29,505 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:29,506 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:29,511 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:29,552 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:29,553 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:29,554 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:29,560 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:29,642 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:29,715 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:29,754 - INFO - Progress: 32 samples processed in 0:02:11.135962\n",
      "Processing samples:  16%|█▌        | 32/200 [02:11<11:38,  4.16s/it]2024-11-16 17:07:29,823 - INFO - Progress: 33 samples processed in 0:02:11.205385\n",
      "2024-11-16 17:07:30,248 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:30,250 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:30,251 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:32,097 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:32,897 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:32,899 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:32,899 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:32,905 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:32,989 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:33,072 - INFO - Progress: 34 samples processed in 0:02:14.454180\n",
      "Processing samples:  17%|█▋        | 34/200 [02:14<08:18,  3.00s/it]2024-11-16 17:07:34,473 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:34,529 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:35,622 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:35,623 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:35,624 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:37,329 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:37,331 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:37,331 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:37,338 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:37,339 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:37,340 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:37,521 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:39,120 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:39,122 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:39,123 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:39,594 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:39,596 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:39,596 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:39,906 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:39,908 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:39,908 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:40,337 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:40,339 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:40,340 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:42,039 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:42,041 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:42,042 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:42,047 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:42,055 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:42,057 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:42,057 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:42,063 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:42,180 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:42,263 - INFO - Progress: 36 samples processed in 0:02:23.645047\n",
      "Processing samples:  18%|█▊        | 35/200 [02:23<12:28,  4.54s/it]2024-11-16 17:07:42,421 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:42,425 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:42,427 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:42,435 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:42,495 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:42,599 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:42,640 - INFO - Progress: 37 samples processed in 0:02:24.022334\n",
      "Processing samples:  18%|█▊        | 36/200 [02:24<09:25,  3.45s/it]2024-11-16 17:07:42,716 - INFO - Progress: 35 samples processed in 0:02:24.098176\n",
      "2024-11-16 17:07:42,946 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:42,948 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:42,949 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:43,219 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:43,221 - INFO - Retrying request to /chat/completions in 0.384385 seconds\n",
      "2024-11-16 17:07:43,920 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:43,921 - INFO - Retrying request to /chat/completions in 0.974842 seconds\n",
      "2024-11-16 17:07:45,167 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:46,420 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:46,421 - INFO - Retrying request to /chat/completions in 0.438392 seconds\n",
      "2024-11-16 17:07:46,748 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:46,791 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:46,865 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:47,146 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:47,147 - INFO - Retrying request to /chat/completions in 0.798211 seconds\n",
      "2024-11-16 17:07:48,272 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:48,587 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:48,589 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:48,589 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:48,836 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:48,838 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:48,839 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:49,271 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:49,273 - INFO - LLMCall function forward\n",
      "2024-11-16 17:07:49,274 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:07:49,898 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:49,899 - INFO - Retrying request to /chat/completions in 0.378331 seconds\n",
      "2024-11-16 17:07:50,379 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:50,384 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:50,385 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:50,555 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:50,557 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:50,559 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:50,592 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:50,592 - INFO - Retrying request to /chat/completions in 0.979461 seconds\n",
      "2024-11-16 17:07:50,942 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:50,944 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:07:50,945 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:07:51,546 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:51,548 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:51,548 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:51,554 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:51,630 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:51,696 - INFO - Progress: 40 samples processed in 0:02:33.078461\n",
      "Processing samples:  19%|█▉        | 38/200 [02:33<10:33,  3.91s/it]2024-11-16 17:07:51,701 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:51,703 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:51,704 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:51,710 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:51,798 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:51,875 - INFO - Progress: 41 samples processed in 0:02:33.256915\n",
      "Processing samples:  20%|█▉        | 39/200 [02:33<08:09,  3.04s/it]2024-11-16 17:07:52,051 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:52,672 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:52,674 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:07:52,674 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:07:52,683 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:52,781 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:07:52,866 - INFO - Progress: 39 samples processed in 0:02:34.248229\n",
      "Processing samples:  20%|██        | 40/200 [02:34<06:44,  2.53s/it]2024-11-16 17:07:53,607 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:53,608 - INFO - Retrying request to /chat/completions in 0.390868 seconds\n",
      "2024-11-16 17:07:54,321 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:54,322 - INFO - Retrying request to /chat/completions in 0.927780 seconds\n",
      "2024-11-16 17:07:55,302 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:55,302 - INFO - Retrying request to /chat/completions in 0.494640 seconds\n",
      "2024-11-16 17:07:55,529 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:56,068 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:56,069 - INFO - Retrying request to /chat/completions in 0.978476 seconds\n",
      "2024-11-16 17:07:57,288 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:57,289 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:07:58,819 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:07:59,310 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:07:59,311 - INFO - Retrying request to /chat/completions in 0.490963 seconds\n",
      "2024-11-16 17:08:00,085 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:00,086 - INFO - Retrying request to /chat/completions in 0.840505 seconds\n",
      "2024-11-16 17:08:00,219 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:01,187 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:01,189 - ERROR - Error processing index 37: RetryError[<Future at 0x73f5446b47a0 state=finished raised RateLimitError>]\n",
      "Processing samples:  20%|██        | 41/200 [02:42<10:44,  4.05s/it]2024-11-16 17:08:01,765 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:01,767 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:01,767 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:02,093 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:02,095 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:02,096 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:05,243 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:05,244 - INFO - Retrying request to /chat/completions in 0.411041 seconds\n",
      "2024-11-16 17:08:05,934 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:05,935 - INFO - Retrying request to /chat/completions in 0.790385 seconds\n",
      "2024-11-16 17:08:06,185 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:06,187 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:06,188 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:06,195 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:06,197 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:06,197 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:06,367 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:06,967 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:06,968 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:08:08,597 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:08,598 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:08,599 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:08,605 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:08,683 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:08,764 - INFO - Progress: 44 samples processed in 0:02:50.146061\n",
      "Processing samples:  21%|██        | 42/200 [02:50<13:12,  5.02s/it]2024-11-16 17:08:09,116 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:09,118 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:09,119 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:09,126 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:09,194 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:09,270 - INFO - Progress: 43 samples processed in 0:02:50.651643\n",
      "Processing samples:  22%|██▏       | 43/200 [02:50<09:48,  3.75s/it]2024-11-16 17:08:10,038 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:10,040 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:10,040 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:12,076 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:12,077 - INFO - Retrying request to /chat/completions in 0.452132 seconds\n",
      "2024-11-16 17:08:12,778 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:12,779 - INFO - Retrying request to /chat/completions in 0.936054 seconds\n",
      "2024-11-16 17:08:12,952 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:12,954 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:12,954 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:13,732 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:13,940 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:13,942 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:13,943 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:13,949 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:14,040 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:14,041 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:08:14,046 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:14,112 - INFO - Progress: 45 samples processed in 0:02:55.493855\n",
      "Processing samples:  22%|██▏       | 44/200 [02:55<10:33,  4.06s/it]2024-11-16 17:08:14,442 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:14,444 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:14,445 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:15,007 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:15,007 - INFO - Retrying request to /chat/completions in 0.488303 seconds\n",
      "2024-11-16 17:08:15,746 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:15,747 - INFO - Retrying request to /chat/completions in 0.875604 seconds\n",
      "2024-11-16 17:08:16,511 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:16,513 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:16,514 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:16,906 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:16,907 - WARNING - Attempt 3 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:08:16,908 - ERROR - All retry attempts failed for GPT response.\n",
      "2024-11-16 17:08:16,908 - ERROR - GPT response for index 41 is empty.\n",
      "Processing samples:  22%|██▎       | 45/200 [02:58<09:32,  3.69s/it]2024-11-16 17:08:17,381 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:17,382 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:17,383 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:17,388 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:17,439 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:17,483 - INFO - Progress: 47 samples processed in 0:02:58.865190\n",
      "Processing samples:  23%|██▎       | 46/200 [02:58<07:08,  2.78s/it]2024-11-16 17:08:17,834 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:18,749 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:18,749 - INFO - Retrying request to /chat/completions in 0.391430 seconds\n",
      "2024-11-16 17:08:19,445 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:19,446 - INFO - Retrying request to /chat/completions in 0.795988 seconds\n",
      "2024-11-16 17:08:19,772 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:19,773 - INFO - Retrying request to /chat/completions in 0.470558 seconds\n",
      "2024-11-16 17:08:20,496 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:21,622 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:21,805 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:21,805 - INFO - Retrying request to /chat/completions in 0.403852 seconds\n",
      "2024-11-16 17:08:21,949 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:21,950 - INFO - Retrying request to /chat/completions in 0.987577 seconds\n",
      "2024-11-16 17:08:21,972 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:21,973 - INFO - Retrying request to /chat/completions in 0.477677 seconds\n",
      "2024-11-16 17:08:22,546 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:22,547 - INFO - Retrying request to /chat/completions in 0.786311 seconds\n",
      "2024-11-16 17:08:22,574 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:22,574 - INFO - Retrying request to /chat/completions in 0.490605 seconds\n",
      "2024-11-16 17:08:22,721 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:22,721 - INFO - Retrying request to /chat/completions in 0.931734 seconds\n",
      "2024-11-16 17:08:24,315 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:24,316 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:24,317 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:24,974 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:25,081 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:25,419 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:25,421 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:25,421 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:25,985 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:25,987 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:25,987 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:26,665 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:26,666 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:26,667 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:26,672 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:26,720 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:26,739 - INFO - Progress: 48 samples processed in 0:03:08.120666\n",
      "Processing samples:  24%|██▎       | 47/200 [03:08<11:57,  4.69s/it]2024-11-16 17:08:26,746 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:26,750 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:26,750 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:27,070 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:27,071 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:27,072 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:27,196 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:27,198 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:27,199 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:28,463 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:28,464 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:28,465 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:28,471 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:28,554 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:28,636 - INFO - Progress: 49 samples processed in 0:03:10.017874\n",
      "Processing samples:  24%|██▍       | 48/200 [03:09<09:47,  3.86s/it]2024-11-16 17:08:29,066 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:29,068 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:29,069 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:29,687 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:29,690 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:29,690 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:29,940 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:29,942 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:29,943 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:29,949 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:30,023 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:30,099 - INFO - Progress: 50 samples processed in 0:03:11.481342\n",
      "Processing samples:  24%|██▍       | 49/200 [03:11<07:55,  3.15s/it]2024-11-16 17:08:30,590 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:30,779 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:30,780 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:30,781 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:30,788 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:30,888 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:30,973 - INFO - Progress: 46 samples processed in 0:03:12.354961\n",
      "Processing samples:  25%|██▌       | 50/200 [03:12<06:10,  2.47s/it]2024-11-16 17:08:32,523 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:33,034 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:33,035 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:33,036 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:34,265 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:34,798 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:34,800 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:34,800 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:35,118 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:35,480 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:35,482 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:35,483 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:36,528 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:36,530 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:36,531 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:36,611 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:36,613 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:36,614 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:36,619 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:36,690 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:36,761 - INFO - Progress: 51 samples processed in 0:03:18.143462\n",
      "2024-11-16 17:08:36,762 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing samples:  26%|██▌       | 51/200 [03:18<08:35,  3.46s/it]2024-11-16 17:08:36,766 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:36,767 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:36,776 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:36,778 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:36,778 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:37,061 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:37,062 - INFO - Retrying request to /chat/completions in 0.462905 seconds\n",
      "2024-11-16 17:08:37,093 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:37,094 - INFO - Retrying request to /chat/completions in 0.382108 seconds\n",
      "2024-11-16 17:08:37,807 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:37,808 - INFO - Retrying request to /chat/completions in 0.999397 seconds\n",
      "2024-11-16 17:08:37,852 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:37,853 - INFO - Retrying request to /chat/completions in 0.769541 seconds\n",
      "2024-11-16 17:08:37,887 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:37,888 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:37,889 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:37,895 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:38,026 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:38,137 - INFO - Progress: 52 samples processed in 0:03:19.519460\n",
      "Processing samples:  26%|██▌       | 52/200 [03:19<06:59,  2.84s/it]2024-11-16 17:08:38,871 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:39,087 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:40,176 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:40,177 - INFO - Retrying request to /chat/completions in 0.453665 seconds\n",
      "2024-11-16 17:08:40,472 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:40,473 - INFO - Retrying request to /chat/completions in 0.442052 seconds\n",
      "2024-11-16 17:08:40,929 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:40,930 - INFO - Retrying request to /chat/completions in 0.806950 seconds\n",
      "2024-11-16 17:08:40,972 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:41,227 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:41,228 - INFO - Retrying request to /chat/completions in 0.783537 seconds\n",
      "2024-11-16 17:08:41,990 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:42,280 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:42,447 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:42,930 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:42,932 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:42,932 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:43,696 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:43,697 - INFO - Retrying request to /chat/completions in 0.408860 seconds\n",
      "2024-11-16 17:08:44,016 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:44,016 - INFO - Retrying request to /chat/completions in 0.497204 seconds\n",
      "2024-11-16 17:08:44,270 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:44,273 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:44,273 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:44,386 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:44,387 - INFO - Retrying request to /chat/completions in 0.850368 seconds\n",
      "2024-11-16 17:08:44,767 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:44,768 - INFO - Retrying request to /chat/completions in 0.857835 seconds\n",
      "2024-11-16 17:08:44,948 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:44,950 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:44,951 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:45,495 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:45,888 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:45,958 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:45,960 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:45,960 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:45,967 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:46,057 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:46,062 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:46,072 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:08:46,073 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:08:46,192 - INFO - Progress: 55 samples processed in 0:03:27.573648\n",
      "Processing samples:  26%|██▋       | 53/200 [03:27<10:46,  4.40s/it]2024-11-16 17:08:46,962 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:46,963 - INFO - Retrying request to /chat/completions in 0.392040 seconds\n",
      "2024-11-16 17:08:47,034 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:47,036 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:08:47,036 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:08:47,042 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:47,102 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:08:47,148 - INFO - Progress: 56 samples processed in 0:03:28.529949\n",
      "Processing samples:  27%|██▋       | 54/200 [03:28<08:11,  3.37s/it]2024-11-16 17:08:47,609 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:47,609 - INFO - Retrying request to /chat/completions in 0.815886 seconds\n",
      "2024-11-16 17:08:47,830 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:47,831 - INFO - Retrying request to /chat/completions in 0.471772 seconds\n",
      "2024-11-16 17:08:48,555 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:48,556 - INFO - Retrying request to /chat/completions in 0.893068 seconds\n",
      "2024-11-16 17:08:48,690 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:49,727 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:50,068 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:50,069 - INFO - Retrying request to /chat/completions in 0.444875 seconds\n",
      "2024-11-16 17:08:50,203 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:50,249 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:50,250 - INFO - Retrying request to /chat/completions in 0.428408 seconds\n",
      "2024-11-16 17:08:50,460 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:50,461 - INFO - Retrying request to /chat/completions in 0.457649 seconds\n",
      "2024-11-16 17:08:50,781 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:50,782 - INFO - Retrying request to /chat/completions in 0.762069 seconds\n",
      "2024-11-16 17:08:50,970 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:50,971 - INFO - Retrying request to /chat/completions in 0.836355 seconds\n",
      "2024-11-16 17:08:51,167 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:51,168 - INFO - Retrying request to /chat/completions in 0.953538 seconds\n",
      "2024-11-16 17:08:51,824 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:51,825 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:08:52,057 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:52,058 - ERROR - Error processing index 53: RetryError[<Future at 0x73f5445af3b0 state=finished raised RateLimitError>]\n",
      "Processing samples:  28%|██▊       | 55/200 [03:33<09:15,  3.83s/it]2024-11-16 17:08:52,377 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:53,682 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:53,682 - INFO - Retrying request to /chat/completions in 0.451216 seconds\n",
      "2024-11-16 17:08:53,968 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:53,969 - INFO - Retrying request to /chat/completions in 0.486574 seconds\n",
      "2024-11-16 17:08:54,457 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:54,458 - INFO - Retrying request to /chat/completions in 0.804906 seconds\n",
      "2024-11-16 17:08:54,738 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:54,738 - INFO - Retrying request to /chat/completions in 0.924634 seconds\n",
      "2024-11-16 17:08:55,604 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:56,039 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:56,170 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:56,172 - ERROR - Error processing index 52: RetryError[<Future at 0x73f54474e240 state=finished raised RateLimitError>]\n",
      "Processing samples:  28%|██▊       | 56/200 [03:37<09:23,  3.92s/it]2024-11-16 17:08:57,582 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:57,583 - INFO - Retrying request to /chat/completions in 0.406795 seconds\n",
      "2024-11-16 17:08:58,016 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:08:58,017 - INFO - LLMCall function forward\n",
      "2024-11-16 17:08:58,018 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:08:58,240 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:58,241 - INFO - Retrying request to /chat/completions in 0.938331 seconds\n",
      "2024-11-16 17:08:59,112 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:08:59,112 - INFO - Retrying request to /chat/completions in 0.382488 seconds\n",
      "2024-11-16 17:08:59,505 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:00,321 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:00,323 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:00,323 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:00,390 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:00,390 - INFO - Retrying request to /chat/completions in 0.839392 seconds\n",
      "2024-11-16 17:09:01,097 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:01,099 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:01,099 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:01,105 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:01,181 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:01,246 - INFO - Progress: 59 samples processed in 0:03:42.627562\n",
      "Processing samples:  28%|██▊       | 57/200 [03:42<10:09,  4.26s/it]2024-11-16 17:09:01,350 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:01,510 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:01,511 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:09:02,434 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:02,435 - INFO - Retrying request to /chat/completions in 0.416391 seconds\n",
      "2024-11-16 17:09:03,190 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:03,191 - INFO - Retrying request to /chat/completions in 0.785446 seconds\n",
      "2024-11-16 17:09:03,762 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:03,764 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:03,765 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:04,292 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:05,176 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:05,303 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:05,305 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:05,305 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:06,255 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:06,256 - INFO - Retrying request to /chat/completions in 0.422241 seconds\n",
      "2024-11-16 17:09:06,328 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:06,329 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:06,330 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:06,336 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:06,409 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:06,469 - INFO - Progress: 60 samples processed in 0:03:47.851058\n",
      "Processing samples:  29%|██▉       | 58/200 [03:47<10:46,  4.55s/it]2024-11-16 17:09:06,841 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:06,843 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:06,843 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:06,949 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:06,950 - INFO - Retrying request to /chat/completions in 0.870891 seconds\n",
      "2024-11-16 17:09:07,756 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:07,757 - INFO - Retrying request to /chat/completions in 0.477453 seconds\n",
      "2024-11-16 17:09:08,078 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:08,079 - ERROR - Error processing index 56: RetryError[<Future at 0x73f51944f200 state=finished raised RateLimitError>]\n",
      "Processing samples:  30%|██▉       | 59/200 [03:49<08:37,  3.67s/it]2024-11-16 17:09:08,518 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:08,518 - INFO - Retrying request to /chat/completions in 0.768889 seconds\n",
      "2024-11-16 17:09:08,766 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:08,767 - INFO - Retrying request to /chat/completions in 0.492607 seconds\n",
      "2024-11-16 17:09:09,455 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:09,456 - INFO - Retrying request to /chat/completions in 0.442723 seconds\n",
      "2024-11-16 17:09:09,564 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:09,624 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:09,625 - INFO - Retrying request to /chat/completions in 0.979100 seconds\n",
      "2024-11-16 17:09:10,180 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:10,181 - INFO - Retrying request to /chat/completions in 0.956076 seconds\n",
      "2024-11-16 17:09:10,875 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:10,876 - INFO - Retrying request to /chat/completions in 0.449334 seconds\n",
      "2024-11-16 17:09:10,880 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:10,880 - WARNING - Attempt 3 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:09:10,881 - ERROR - All retry attempts failed for GPT response.\n",
      "2024-11-16 17:09:10,881 - ERROR - GPT response for index 57 is empty.\n",
      "Processing samples:  30%|███       | 60/200 [03:52<07:57,  3.41s/it]2024-11-16 17:09:11,399 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:11,399 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:09:11,576 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:11,577 - INFO - Retrying request to /chat/completions in 0.965913 seconds\n",
      "2024-11-16 17:09:12,095 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:12,857 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:14,122 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:14,123 - INFO - Retrying request to /chat/completions in 0.398267 seconds\n",
      "2024-11-16 17:09:14,364 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:14,366 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:14,367 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:14,768 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:14,769 - INFO - Retrying request to /chat/completions in 0.931757 seconds\n",
      "2024-11-16 17:09:15,033 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:16,028 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:16,033 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:16,035 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:16,035 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:16,303 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:16,305 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:16,306 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:17,752 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:17,753 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:17,754 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:17,763 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:17,869 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:17,951 - INFO - Progress: 63 samples processed in 0:03:59.332882\n",
      "Processing samples:  30%|███       | 61/200 [03:59<10:26,  4.51s/it]2024-11-16 17:09:18,031 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:18,031 - INFO - Retrying request to /chat/completions in 0.460597 seconds\n",
      "2024-11-16 17:09:18,218 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:18,219 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:18,220 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:18,650 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:18,650 - INFO - Retrying request to /chat/completions in 0.434354 seconds\n",
      "2024-11-16 17:09:19,233 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:19,235 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:19,235 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:19,242 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:19,326 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:19,386 - INFO - Progress: 64 samples processed in 0:04:00.768074\n",
      "Processing samples:  31%|███       | 62/200 [04:00<08:14,  3.59s/it]2024-11-16 17:09:19,489 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:19,490 - INFO - Retrying request to /chat/completions in 0.813472 seconds\n",
      "2024-11-16 17:09:19,513 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:19,514 - INFO - Retrying request to /chat/completions in 0.826150 seconds\n",
      "2024-11-16 17:09:20,574 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:20,642 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:20,643 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:09:21,873 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:22,296 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:22,297 - INFO - Retrying request to /chat/completions in 0.416221 seconds\n",
      "2024-11-16 17:09:22,791 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:22,792 - INFO - Retrying request to /chat/completions in 0.430666 seconds\n",
      "2024-11-16 17:09:22,962 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:09:22,963 - INFO - Retrying request to /chat/completions in 0.998606 seconds\n",
      "2024-11-16 17:09:25,161 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:25,162 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:25,163 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:26,626 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:27,506 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:27,508 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:27,509 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:27,513 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:27,514 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:27,515 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:29,510 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:29,511 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:29,512 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:30,994 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:30,996 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:30,997 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:31,002 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:31,084 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:31,161 - INFO - Progress: 61 samples processed in 0:04:12.542785\n",
      "Processing samples:  32%|███▏      | 63/200 [04:12<13:47,  6.04s/it]2024-11-16 17:09:31,445 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:31,447 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:31,447 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:31,452 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:31,545 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:31,636 - INFO - Progress: 65 samples processed in 0:04:13.018118\n",
      "Processing samples:  32%|███▏      | 64/200 [04:12<09:54,  4.37s/it]2024-11-16 17:09:32,059 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:32,060 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:32,061 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:32,709 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:34,538 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:34,540 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:34,540 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:34,915 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:34,917 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:34,918 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:34,924 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:34,999 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:35,059 - INFO - Progress: 66 samples processed in 0:04:16.441314\n",
      "Processing samples:  32%|███▎      | 65/200 [04:16<09:11,  4.09s/it]2024-11-16 17:09:36,108 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:36,116 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:38,111 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:38,112 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:38,113 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:39,449 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:39,808 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:39,810 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:39,811 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:39,816 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:39,864 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:39,866 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:39,873 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:39,874 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:39,920 - INFO - Progress: 62 samples processed in 0:04:21.302079\n",
      "Processing samples:  33%|███▎      | 66/200 [04:21<09:38,  4.32s/it]2024-11-16 17:09:40,152 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:40,154 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:40,155 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:42,081 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:42,082 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:42,083 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:43,981 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:43,983 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:43,984 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:43,993 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:43,995 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:43,995 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:44,931 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:45,471 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:45,473 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:45,474 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:45,930 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:45,932 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:45,933 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:45,933 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:45,940 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:45,948 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:45,948 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:45,954 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:46,053 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:46,102 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:46,205 - INFO - Progress: 68 samples processed in 0:04:27.587311\n",
      "Processing samples:  34%|███▎      | 67/200 [04:27<10:52,  4.91s/it]2024-11-16 17:09:46,235 - INFO - Progress: 67 samples processed in 0:04:27.617182\n",
      "2024-11-16 17:09:46,737 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:46,739 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:46,740 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:46,746 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:46,832 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:46,920 - INFO - Progress: 69 samples processed in 0:04:28.301671\n",
      "Processing samples:  34%|███▍      | 69/200 [04:28<06:07,  2.81s/it]2024-11-16 17:09:47,247 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:47,249 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:47,250 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:49,703 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:49,705 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:09:49,705 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:09:50,596 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:51,077 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:51,336 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:51,961 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:51,963 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:09:51,963 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:09:51,969 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:52,057 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:09:52,148 - INFO - Progress: 70 samples processed in 0:04:33.529718\n",
      "Processing samples:  35%|███▌      | 70/200 [04:33<07:23,  3.41s/it]2024-11-16 17:09:53,943 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:53,945 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:53,946 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:54,365 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:54,389 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:54,390 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:09:57,884 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:09:57,888 - INFO - LLMCall function forward\n",
      "2024-11-16 17:09:57,888 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:00,582 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:01,477 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:01,479 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:01,479 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:01,501 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:01,502 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:01,503 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:01,513 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:01,514 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:01,515 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:07,050 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:07,052 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:07,053 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:08,003 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:08,006 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:08,006 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:08,011 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:08,096 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:08,115 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:08,123 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:08,123 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:08,129 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:08,247 - INFO - Progress: 73 samples processed in 0:04:49.629331\n",
      "Processing samples:  36%|███▌      | 71/200 [04:49<14:27,  6.73s/it]2024-11-16 17:10:08,286 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:08,366 - INFO - Progress: 72 samples processed in 0:04:49.747531\n",
      "Processing samples:  36%|███▌      | 72/200 [04:49<10:31,  4.93s/it]2024-11-16 17:10:08,547 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:08,549 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:08,549 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:08,556 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:08,629 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:08,707 - INFO - Progress: 71 samples processed in 0:04:50.088579\n",
      "Processing samples:  36%|███▋      | 73/200 [04:50<07:43,  3.65s/it]2024-11-16 17:10:14,109 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:14,111 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:14,112 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:14,333 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:14,388 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:14,389 - INFO - Retrying request to /chat/completions in 0.382855 seconds\n",
      "2024-11-16 17:10:15,052 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:15,053 - INFO - Retrying request to /chat/completions in 0.750599 seconds\n",
      "2024-11-16 17:10:16,055 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:16,394 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:16,405 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:17,163 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:17,165 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:17,166 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:17,376 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:17,377 - INFO - Retrying request to /chat/completions in 0.494697 seconds\n",
      "2024-11-16 17:10:17,425 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:17,426 - INFO - Retrying request to /chat/completions in 0.401123 seconds\n",
      "2024-11-16 17:10:18,097 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:18,098 - INFO - Retrying request to /chat/completions in 0.901109 seconds\n",
      "2024-11-16 17:10:18,122 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:18,123 - INFO - Retrying request to /chat/completions in 0.944990 seconds\n",
      "2024-11-16 17:10:18,341 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:18,343 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:18,344 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:18,654 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:18,655 - INFO - Retrying request to /chat/completions in 0.425356 seconds\n",
      "2024-11-16 17:10:18,702 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:18,704 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:18,705 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:18,968 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:18,969 - INFO - Retrying request to /chat/completions in 0.437674 seconds\n",
      "2024-11-16 17:10:19,247 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:19,366 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:19,371 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:19,372 - INFO - Retrying request to /chat/completions in 0.951059 seconds\n",
      "2024-11-16 17:10:19,658 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:19,659 - INFO - Retrying request to /chat/completions in 0.781799 seconds\n",
      "2024-11-16 17:10:20,502 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:20,503 - INFO - Retrying request to /chat/completions in 0.473022 seconds\n",
      "2024-11-16 17:10:20,612 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:20,714 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:21,264 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:21,265 - INFO - Retrying request to /chat/completions in 0.984695 seconds\n",
      "2024-11-16 17:10:21,612 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:21,613 - INFO - Retrying request to /chat/completions in 0.499056 seconds\n",
      "2024-11-16 17:10:21,875 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:21,876 - INFO - Retrying request to /chat/completions in 0.411679 seconds\n",
      "2024-11-16 17:10:21,995 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:21,996 - INFO - Retrying request to /chat/completions in 0.384129 seconds\n",
      "2024-11-16 17:10:22,372 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:22,373 - INFO - Retrying request to /chat/completions in 0.818104 seconds\n",
      "2024-11-16 17:10:22,525 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:22,537 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:22,538 - INFO - Retrying request to /chat/completions in 0.883412 seconds\n",
      "2024-11-16 17:10:22,629 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:22,629 - INFO - Retrying request to /chat/completions in 0.804239 seconds\n",
      "2024-11-16 17:10:23,462 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:23,718 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:23,739 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:23,874 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:23,875 - INFO - Retrying request to /chat/completions in 0.485706 seconds\n",
      "2024-11-16 17:10:24,607 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:24,608 - INFO - Retrying request to /chat/completions in 0.900849 seconds\n",
      "2024-11-16 17:10:25,238 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:25,239 - INFO - Retrying request to /chat/completions in 0.490729 seconds\n",
      "2024-11-16 17:10:25,765 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:25,974 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:25,974 - INFO - Retrying request to /chat/completions in 0.419612 seconds\n",
      "2024-11-16 17:10:26,044 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:26,045 - INFO - Retrying request to /chat/completions in 0.818020 seconds\n",
      "2024-11-16 17:10:26,693 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:26,695 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:26,695 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:26,701 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:26,708 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:26,709 - INFO - Retrying request to /chat/completions in 0.929022 seconds\n",
      "2024-11-16 17:10:26,771 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:26,838 - INFO - Progress: 74 samples processed in 0:05:08.220265\n",
      "Processing samples:  37%|███▋      | 74/200 [05:08<16:20,  7.78s/it]2024-11-16 17:10:27,175 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:27,981 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:29,637 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:29,638 - INFO - Retrying request to /chat/completions in 0.455362 seconds\n",
      "2024-11-16 17:10:29,831 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:29,832 - INFO - Retrying request to /chat/completions in 0.425788 seconds\n",
      "2024-11-16 17:10:30,358 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:30,358 - INFO - Retrying request to /chat/completions in 0.857889 seconds\n",
      "2024-11-16 17:10:30,559 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:30,560 - INFO - Retrying request to /chat/completions in 0.850829 seconds\n",
      "2024-11-16 17:10:31,033 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:31,109 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:31,110 - INFO - Retrying request to /chat/completions in 0.416164 seconds\n",
      "2024-11-16 17:10:31,507 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:31,711 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:31,802 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:31,802 - INFO - Retrying request to /chat/completions in 0.949652 seconds\n",
      "2024-11-16 17:10:32,479 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:32,481 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:32,481 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:33,060 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:34,420 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:34,421 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:34,422 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:36,132 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:36,134 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:36,135 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:36,142 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:36,233 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:36,237 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:36,238 - INFO - Retrying request to /chat/completions in 0.497300 seconds\n",
      "2024-11-16 17:10:36,327 - INFO - Progress: 78 samples processed in 0:05:17.709459\n",
      "Processing samples:  38%|███▊      | 75/200 [05:17<17:14,  8.28s/it]2024-11-16 17:10:36,418 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:36,419 - INFO - Retrying request to /chat/completions in 0.416118 seconds\n",
      "2024-11-16 17:10:36,993 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:36,994 - INFO - Retrying request to /chat/completions in 0.794715 seconds\n",
      "2024-11-16 17:10:37,085 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:10:37,085 - INFO - Retrying request to /chat/completions in 0.933851 seconds\n",
      "2024-11-16 17:10:39,340 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:39,342 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:39,342 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:39,713 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:39,715 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:39,716 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:40,277 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:40,279 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:40,280 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:40,462 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:40,464 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:40,464 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:40,471 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:40,554 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:40,594 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:40,629 - INFO - Progress: 77 samples processed in 0:05:22.011389\n",
      "Processing samples:  38%|███▊      | 76/200 [05:21<14:42,  7.11s/it]2024-11-16 17:10:40,669 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:40,671 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:40,671 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:40,677 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:40,742 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:40,797 - INFO - Progress: 75 samples processed in 0:05:22.178812\n",
      "Processing samples:  38%|███▊      | 77/200 [05:22<10:22,  5.07s/it]2024-11-16 17:10:41,800 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:41,802 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:41,802 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:41,866 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:41,868 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:41,868 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:41,874 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:41,953 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:42,018 - INFO - Progress: 76 samples processed in 0:05:23.399755\n",
      "Processing samples:  39%|███▉      | 78/200 [05:23<07:58,  3.93s/it]2024-11-16 17:10:44,423 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:44,425 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:44,426 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:44,643 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:44,702 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:45,549 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:45,551 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:45,551 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:45,557 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:45,631 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:45,712 - INFO - Progress: 79 samples processed in 0:05:27.093708\n",
      "Processing samples:  40%|███▉      | 79/200 [05:27<07:46,  3.86s/it]2024-11-16 17:10:46,084 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:46,692 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:46,694 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:46,695 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:46,780 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:46,782 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:46,783 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:47,928 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:47,929 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:47,930 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:48,941 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:48,943 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:48,944 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:48,979 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:48,981 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:48,981 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:49,766 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:49,768 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:49,768 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:49,928 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:49,930 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:49,931 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:49,936 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:50,021 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:50,059 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:50,096 - INFO - Progress: 81 samples processed in 0:05:31.478378\n",
      "Processing samples:  40%|████      | 80/200 [05:31<08:01,  4.01s/it]2024-11-16 17:10:50,283 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:50,285 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:50,285 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:50,291 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:50,534 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:50,608 - INFO - Progress: 80 samples processed in 0:05:31.989914\n",
      "Processing samples:  40%|████      | 81/200 [05:31<05:53,  2.97s/it]2024-11-16 17:10:50,650 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:50,652 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:50,652 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:50,660 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:50,735 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:50,804 - INFO - Progress: 82 samples processed in 0:05:32.186114\n",
      "Processing samples:  41%|████      | 82/200 [05:32<04:12,  2.14s/it]2024-11-16 17:10:51,797 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:51,800 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:51,800 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:54,276 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:54,277 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:54,278 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:54,325 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:54,449 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:55,026 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:55,598 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:55,599 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:55,600 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:55,607 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:55,734 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:55,868 - INFO - Progress: 83 samples processed in 0:05:37.249706\n",
      "Processing samples:  42%|████▏     | 83/200 [05:37<05:52,  3.01s/it]2024-11-16 17:10:56,124 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:56,126 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:56,126 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:56,652 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:56,654 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:56,655 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:57,349 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:57,350 - INFO - LLMCall function forward\n",
      "2024-11-16 17:10:57,351 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:10:58,699 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:58,701 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:58,702 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:58,852 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:58,855 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:58,855 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:59,501 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:59,677 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:59,679 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:59,679 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:59,686 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:59,767 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:59,828 - INFO - Progress: 86 samples processed in 0:05:41.210066\n",
      "Processing samples:  42%|████▏     | 84/200 [05:41<06:22,  3.30s/it]2024-11-16 17:10:59,830 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:59,833 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:10:59,833 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:10:59,903 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:10:59,905 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:10:59,905 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:10:59,912 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:10:59,995 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:00,068 - INFO - Progress: 84 samples processed in 0:05:41.449671\n",
      "Processing samples:  42%|████▎     | 85/200 [05:41<04:33,  2.38s/it]2024-11-16 17:11:00,137 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:00,139 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:00,139 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:00,752 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:00,754 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:00,754 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:00,759 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:00,826 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:00,897 - INFO - Progress: 85 samples processed in 0:05:42.279316\n",
      "Processing samples:  43%|████▎     | 86/200 [05:42<03:38,  1.92s/it]2024-11-16 17:11:03,057 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:03,059 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:03,060 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:03,806 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:04,251 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:04,292 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:04,293 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:04,294 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:04,299 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:04,370 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:04,453 - INFO - Progress: 87 samples processed in 0:05:45.834503\n",
      "Processing samples:  44%|████▎     | 87/200 [05:45<04:32,  2.41s/it]2024-11-16 17:11:05,167 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:05,168 - INFO - Retrying request to /chat/completions in 0.479448 seconds\n",
      "2024-11-16 17:11:05,319 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:05,911 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:05,912 - INFO - Retrying request to /chat/completions in 0.925261 seconds\n",
      "2024-11-16 17:11:06,295 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:06,297 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:06,298 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:07,091 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:07,398 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:07,399 - INFO - Retrying request to /chat/completions in 0.394782 seconds\n",
      "2024-11-16 17:11:08,085 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:08,085 - INFO - Retrying request to /chat/completions in 0.958114 seconds\n",
      "2024-11-16 17:11:08,091 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:08,095 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:08,096 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:08,368 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:08,369 - INFO - Retrying request to /chat/completions in 0.393173 seconds\n",
      "2024-11-16 17:11:08,382 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:08,382 - INFO - Retrying request to /chat/completions in 0.492459 seconds\n",
      "2024-11-16 17:11:08,888 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:08,891 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:08,891 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:09,011 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:09,011 - INFO - Retrying request to /chat/completions in 0.792955 seconds\n",
      "2024-11-16 17:11:09,137 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:09,138 - INFO - Retrying request to /chat/completions in 0.986886 seconds\n",
      "2024-11-16 17:11:09,169 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:09,170 - INFO - Retrying request to /chat/completions in 0.470775 seconds\n",
      "2024-11-16 17:11:09,290 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:09,291 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:11:09,889 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:09,890 - INFO - Retrying request to /chat/completions in 0.779112 seconds\n",
      "2024-11-16 17:11:10,053 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:10,408 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:10,928 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:11,332 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:11,333 - INFO - Retrying request to /chat/completions in 0.437322 seconds\n",
      "2024-11-16 17:11:11,703 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:11,704 - INFO - Retrying request to /chat/completions in 0.453147 seconds\n",
      "2024-11-16 17:11:12,019 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:12,020 - INFO - Retrying request to /chat/completions in 0.833923 seconds\n",
      "2024-11-16 17:11:12,232 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:12,233 - INFO - Retrying request to /chat/completions in 0.485788 seconds\n",
      "2024-11-16 17:11:12,434 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:12,435 - INFO - Retrying request to /chat/completions in 0.822909 seconds\n",
      "2024-11-16 17:11:13,017 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:13,018 - INFO - Retrying request to /chat/completions in 0.996747 seconds\n",
      "2024-11-16 17:11:13,100 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:13,530 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:14,264 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:16,154 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:16,155 - INFO - Retrying request to /chat/completions in 0.432196 seconds\n",
      "2024-11-16 17:11:16,176 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:16,176 - INFO - Retrying request to /chat/completions in 0.462294 seconds\n",
      "2024-11-16 17:11:16,527 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:16,529 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:16,529 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:16,884 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:16,885 - INFO - Retrying request to /chat/completions in 0.889956 seconds\n",
      "2024-11-16 17:11:16,906 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:16,907 - INFO - Retrying request to /chat/completions in 0.789317 seconds\n",
      "2024-11-16 17:11:17,632 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:17,634 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:17,634 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:17,641 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:17,719 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:17,803 - INFO - Progress: 90 samples processed in 0:05:59.185281\n",
      "Processing samples:  44%|████▍     | 88/200 [05:59<10:37,  5.69s/it]2024-11-16 17:11:17,965 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:18,064 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:18,195 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:20,485 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:20,486 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:20,487 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:22,088 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:22,089 - INFO - Retrying request to /chat/completions in 0.465585 seconds\n",
      "2024-11-16 17:11:22,099 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:22,100 - INFO - Retrying request to /chat/completions in 0.458623 seconds\n",
      "2024-11-16 17:11:22,112 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:22,353 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:22,355 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:22,355 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:22,811 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:22,811 - INFO - Retrying request to /chat/completions in 0.962698 seconds\n",
      "2024-11-16 17:11:22,831 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:22,831 - INFO - Retrying request to /chat/completions in 0.884523 seconds\n",
      "2024-11-16 17:11:23,383 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:23,385 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:23,385 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:23,391 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:23,474 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:23,542 - INFO - Progress: 91 samples processed in 0:06:04.923893\n",
      "Processing samples:  44%|████▍     | 89/200 [06:04<10:33,  5.70s/it]2024-11-16 17:11:23,971 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:23,972 - ERROR - Error processing index 88: RetryError[<Future at 0x73f519480260 state=finished raised RateLimitError>]\n",
      "Processing samples:  45%|████▌     | 90/200 [06:05<07:33,  4.12s/it]2024-11-16 17:11:24,028 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:24,031 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:24,032 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:24,065 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:24,969 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:11:24,970 - INFO - Retrying request to /chat/completions in 0.497020 seconds\n",
      "2024-11-16 17:11:27,351 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:27,352 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:27,353 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:28,146 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:28,206 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:31,427 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:31,429 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:31,430 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:31,436 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:31,504 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:31,578 - INFO - Progress: 92 samples processed in 0:06:12.959784\n",
      "Processing samples:  46%|████▌     | 91/200 [06:12<09:23,  5.17s/it]2024-11-16 17:11:31,923 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:31,925 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:31,925 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:31,932 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:32,023 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:32,097 - INFO - Progress: 88 samples processed in 0:06:13.478736\n",
      "Processing samples:  46%|████▌     | 92/200 [06:13<06:47,  3.77s/it]2024-11-16 17:11:32,305 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:32,307 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:32,307 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:32,729 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:32,731 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:32,731 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:35,604 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:35,606 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:35,607 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:35,981 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:35,983 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:35,983 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:36,570 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:36,692 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:39,209 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:39,211 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:39,212 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:39,219 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:39,230 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:39,232 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:39,232 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:39,238 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:39,399 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:39,443 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:39,614 - INFO - Progress: 94 samples processed in 0:06:20.995719\n",
      "Processing samples:  46%|████▋     | 93/200 [06:20<08:43,  4.90s/it]2024-11-16 17:11:39,663 - INFO - Progress: 93 samples processed in 0:06:21.045127\n",
      "2024-11-16 17:11:41,495 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:41,497 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:41,497 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:41,844 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:41,846 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:41,847 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:44,340 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:44,342 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:44,342 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:44,806 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:44,865 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:45,121 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:45,123 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:45,123 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:45,901 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:45,903 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:45,904 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:45,910 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:45,976 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:46,025 - INFO - Progress: 95 samples processed in 0:06:27.407356\n",
      "Processing samples:  48%|████▊     | 95/200 [06:27<07:12,  4.12s/it]2024-11-16 17:11:47,057 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:47,060 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:47,060 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:47,243 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:47,245 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:47,246 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:47,856 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:47,858 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:47,859 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:47,865 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:47,965 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:48,044 - INFO - Progress: 96 samples processed in 0:06:29.425572\n",
      "Processing samples:  48%|████▊     | 96/200 [06:29<06:14,  3.60s/it]2024-11-16 17:11:50,547 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:50,549 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:50,550 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:50,693 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:50,695 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:11:50,696 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:11:50,935 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:52,707 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:52,781 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:52,783 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:52,784 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:52,789 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:52,860 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:52,940 - INFO - Progress: 98 samples processed in 0:06:34.322338\n",
      "Processing samples:  48%|████▊     | 97/200 [06:34<06:45,  3.94s/it]2024-11-16 17:11:53,395 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:53,397 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:11:53,397 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:11:53,403 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:53,473 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:11:53,543 - INFO - Progress: 97 samples processed in 0:06:34.924884\n",
      "Processing samples:  49%|████▉     | 98/200 [06:34<05:08,  3.03s/it]2024-11-16 17:11:56,699 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:56,701 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:11:56,703 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:56,703 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:11:56,705 - INFO - LLMCall function forward\n",
      "2024-11-16 17:11:56,705 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:00,269 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:00,275 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:02,458 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:02,460 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:02,461 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:02,656 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:02,658 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:02,659 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:03,864 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:03,866 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:03,866 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:04,146 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:04,149 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:04,149 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:04,333 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:04,335 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:04,335 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:04,340 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:04,402 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:04,449 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:04,450 - INFO - Retrying request to /chat/completions in 0.471974 seconds\n",
      "2024-11-16 17:12:04,492 - INFO - Progress: 99 samples processed in 0:06:45.873829\n",
      "Processing samples:  50%|████▉     | 99/200 [06:45<08:49,  5.25s/it]2024-11-16 17:12:05,196 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:05,196 - INFO - Retrying request to /chat/completions in 0.984376 seconds\n",
      "2024-11-16 17:12:05,888 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:05,890 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:05,890 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:05,899 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:05,980 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:06,053 - INFO - Progress: 100 samples processed in 0:06:47.434617\n",
      "Processing samples:  50%|█████     | 100/200 [06:47<06:59,  4.19s/it]2024-11-16 17:12:06,485 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:06,535 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:06,537 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:06,538 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:06,796 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:06,797 - INFO - Retrying request to /chat/completions in 0.378653 seconds\n",
      "2024-11-16 17:12:07,450 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:07,451 - INFO - Retrying request to /chat/completions in 0.974889 seconds\n",
      "2024-11-16 17:12:07,734 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:07,735 - INFO - Retrying request to /chat/completions in 0.399451 seconds\n",
      "2024-11-16 17:12:08,444 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:08,450 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:08,451 - INFO - Retrying request to /chat/completions in 0.900918 seconds\n",
      "2024-11-16 17:12:08,690 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:09,601 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:09,967 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:09,968 - INFO - Retrying request to /chat/completions in 0.440209 seconds\n",
      "2024-11-16 17:12:10,297 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:10,682 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:10,683 - INFO - Retrying request to /chat/completions in 0.909826 seconds\n",
      "2024-11-16 17:12:10,924 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:10,924 - INFO - Retrying request to /chat/completions in 0.489821 seconds\n",
      "2024-11-16 17:12:10,942 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:10,943 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:10,944 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:11,686 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:11,687 - INFO - Retrying request to /chat/completions in 0.882912 seconds\n",
      "2024-11-16 17:12:11,837 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:11,838 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:11,840 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:11,841 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:12,823 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:12,844 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:12,846 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:12,846 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:13,710 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:13,711 - INFO - Retrying request to /chat/completions in 0.490218 seconds\n",
      "2024-11-16 17:12:13,797 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:13,799 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:13,800 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:14,164 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:14,166 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:14,166 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:14,171 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:14,179 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:14,180 - INFO - Retrying request to /chat/completions in 0.438436 seconds\n",
      "2024-11-16 17:12:14,254 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:14,344 - INFO - Progress: 103 samples processed in 0:06:55.725595\n",
      "Processing samples:  50%|█████     | 101/200 [06:55<08:52,  5.38s/it]2024-11-16 17:12:14,496 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:14,496 - INFO - Retrying request to /chat/completions in 0.771187 seconds\n",
      "2024-11-16 17:12:14,889 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:14,890 - INFO - Retrying request to /chat/completions in 0.833642 seconds\n",
      "2024-11-16 17:12:15,279 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:15,282 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:15,283 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:15,290 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:15,378 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:15,458 - INFO - Progress: 104 samples processed in 0:06:56.840346\n",
      "Processing samples:  51%|█████     | 102/200 [06:56<06:44,  4.13s/it]2024-11-16 17:12:15,539 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:15,997 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:17,085 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:17,086 - INFO - Retrying request to /chat/completions in 0.460621 seconds\n",
      "2024-11-16 17:12:17,808 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:17,809 - INFO - Retrying request to /chat/completions in 0.844610 seconds\n",
      "2024-11-16 17:12:18,696 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:18,849 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:18,849 - INFO - Retrying request to /chat/completions in 0.424462 seconds\n",
      "2024-11-16 17:12:18,930 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:19,537 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:19,538 - INFO - Retrying request to /chat/completions in 0.838984 seconds\n",
      "2024-11-16 17:12:19,654 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:19,654 - INFO - Retrying request to /chat/completions in 0.481015 seconds\n",
      "2024-11-16 17:12:19,738 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:19,739 - INFO - Retrying request to /chat/completions in 0.418658 seconds\n",
      "2024-11-16 17:12:20,377 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:20,379 - INFO - Retrying request to /chat/completions in 0.981748 seconds\n",
      "2024-11-16 17:12:20,411 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:20,412 - INFO - Retrying request to /chat/completions in 0.781558 seconds\n",
      "2024-11-16 17:12:20,624 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:20,625 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:12:21,446 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:21,447 - ERROR - Error processing index 100: RetryError[<Future at 0x73f519a132c0 state=finished raised RateLimitError>]\n",
      "Processing samples:  52%|█████▏    | 103/200 [07:02<07:33,  4.68s/it]2024-11-16 17:12:21,630 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:22,922 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:22,923 - INFO - Retrying request to /chat/completions in 0.436929 seconds\n",
      "2024-11-16 17:12:23,762 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:23,762 - INFO - Retrying request to /chat/completions in 0.809304 seconds\n",
      "2024-11-16 17:12:23,901 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:23,902 - INFO - Retrying request to /chat/completions in 0.401619 seconds\n",
      "2024-11-16 17:12:24,557 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:24,558 - INFO - Retrying request to /chat/completions in 0.901936 seconds\n",
      "2024-11-16 17:12:24,838 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:25,706 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:25,707 - ERROR - Error processing index 101: RetryError[<Future at 0x73f519ad62d0 state=finished raised RateLimitError>]\n",
      "Processing samples:  52%|█████▏    | 104/200 [07:07<07:17,  4.55s/it]2024-11-16 17:12:25,777 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:27,708 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:27,726 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:27,727 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:28,058 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:28,062 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:28,062 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:29,553 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:29,672 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:29,674 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:29,675 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:29,799 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:30,225 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:30,227 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:30,228 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:30,552 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:30,554 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:30,555 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:30,565 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:30,654 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:30,730 - INFO - Progress: 107 samples processed in 0:07:12.112427\n",
      "Processing samples:  52%|█████▎    | 105/200 [07:12<07:25,  4.69s/it]2024-11-16 17:12:31,363 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:31,364 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:31,365 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:31,371 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:31,471 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:31,571 - INFO - Progress: 105 samples processed in 0:07:12.953347\n",
      "Processing samples:  53%|█████▎    | 106/200 [07:12<05:33,  3.55s/it]2024-11-16 17:12:31,878 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:31,880 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:31,881 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:32,005 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:32,007 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:32,008 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:34,317 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:34,319 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:34,320 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:34,754 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:34,756 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:34,757 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:35,215 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:35,309 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:35,311 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:35,311 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:35,317 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:35,450 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:35,578 - INFO - Progress: 108 samples processed in 0:07:16.959999\n",
      "Processing samples:  54%|█████▎    | 107/200 [07:16<05:42,  3.68s/it]2024-11-16 17:12:35,721 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:35,769 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:35,770 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:35,771 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:35,776 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:35,865 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:35,944 - INFO - Progress: 106 samples processed in 0:07:17.325684\n",
      "Processing samples:  54%|█████▍    | 108/200 [07:17<04:07,  2.69s/it]2024-11-16 17:12:36,690 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:36,693 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:36,693 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:38,045 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:38,047 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:38,047 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:38,959 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:38,961 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:38,962 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:39,022 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:39,023 - INFO - Retrying request to /chat/completions in 0.414240 seconds\n",
      "2024-11-16 17:12:39,437 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:39,705 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:39,705 - INFO - Retrying request to /chat/completions in 0.414683 seconds\n",
      "2024-11-16 17:12:39,707 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:39,707 - INFO - Retrying request to /chat/completions in 0.805481 seconds\n",
      "2024-11-16 17:12:39,805 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:40,057 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:40,058 - INFO - Retrying request to /chat/completions in 0.439902 seconds\n",
      "2024-11-16 17:12:40,081 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:40,082 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:40,083 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:40,089 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:40,178 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:40,261 - INFO - Progress: 109 samples processed in 0:07:21.642733\n",
      "Processing samples:  55%|█████▍    | 109/200 [07:21<04:49,  3.18s/it]2024-11-16 17:12:40,440 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:40,441 - INFO - Retrying request to /chat/completions in 0.989903 seconds\n",
      "2024-11-16 17:12:40,746 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:40,748 - INFO - Retrying request to /chat/completions in 0.849213 seconds\n",
      "2024-11-16 17:12:40,789 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:41,702 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:41,845 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:42,088 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:42,089 - INFO - Retrying request to /chat/completions in 0.443781 seconds\n",
      "2024-11-16 17:12:42,834 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:42,835 - INFO - Retrying request to /chat/completions in 0.975381 seconds\n",
      "2024-11-16 17:12:42,978 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:42,979 - INFO - Retrying request to /chat/completions in 0.489597 seconds\n",
      "2024-11-16 17:12:43,123 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:43,124 - INFO - Retrying request to /chat/completions in 0.485093 seconds\n",
      "2024-11-16 17:12:43,716 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:43,716 - INFO - Retrying request to /chat/completions in 0.928010 seconds\n",
      "2024-11-16 17:12:43,869 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:43,870 - INFO - Retrying request to /chat/completions in 0.920134 seconds\n",
      "2024-11-16 17:12:44,084 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:44,983 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:45,033 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:45,371 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:45,372 - INFO - Retrying request to /chat/completions in 0.391294 seconds\n",
      "2024-11-16 17:12:45,638 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:46,022 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:46,023 - INFO - Retrying request to /chat/completions in 0.864963 seconds\n",
      "2024-11-16 17:12:47,119 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:47,120 - INFO - Retrying request to /chat/completions in 0.451117 seconds\n",
      "2024-11-16 17:12:47,132 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:47,304 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:47,305 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:47,306 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:47,806 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:47,807 - INFO - Retrying request to /chat/completions in 0.835674 seconds\n",
      "2024-11-16 17:12:47,854 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:47,854 - INFO - Retrying request to /chat/completions in 0.488995 seconds\n",
      "2024-11-16 17:12:48,624 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:48,625 - INFO - Retrying request to /chat/completions in 0.798394 seconds\n",
      "2024-11-16 17:12:48,993 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:48,994 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:48,995 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:48,999 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:49,665 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:49,988 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:49,989 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:49,990 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:49,996 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:50,082 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:50,163 - INFO - Progress: 113 samples processed in 0:07:31.545402\n",
      "Processing samples:  55%|█████▌    | 110/200 [07:31<07:47,  5.19s/it]2024-11-16 17:12:50,428 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:50,430 - INFO - Retrying request to /chat/completions in 0.466409 seconds\n",
      "2024-11-16 17:12:51,495 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:51,496 - INFO - Retrying request to /chat/completions in 0.998706 seconds\n",
      "2024-11-16 17:12:51,568 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:51,569 - INFO - Retrying request to /chat/completions in 0.376089 seconds\n",
      "2024-11-16 17:12:52,194 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:52,194 - INFO - Retrying request to /chat/completions in 0.862745 seconds\n",
      "2024-11-16 17:12:52,383 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:52,384 - INFO - Retrying request to /chat/completions in 0.433262 seconds\n",
      "2024-11-16 17:12:52,760 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:53,085 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:53,086 - INFO - Retrying request to /chat/completions in 0.855073 seconds\n",
      "2024-11-16 17:12:53,333 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:53,844 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:54,238 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:55,619 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:55,620 - INFO - LLMCall function forward\n",
      "2024-11-16 17:12:55,621 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:12:55,936 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:55,937 - INFO - Retrying request to /chat/completions in 0.411034 seconds\n",
      "2024-11-16 17:12:56,596 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:56,597 - INFO - Retrying request to /chat/completions in 0.778356 seconds\n",
      "2024-11-16 17:12:57,381 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:57,383 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:12:57,383 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:12:57,649 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:57,650 - ERROR - Error processing index 109: RetryError[<Future at 0x73f545df3ad0 state=finished raised RateLimitError>]\n",
      "Processing samples:  56%|█████▌    | 111/200 [07:39<08:43,  5.88s/it]2024-11-16 17:12:57,794 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:57,795 - INFO - Retrying request to /chat/completions in 0.413973 seconds\n",
      "2024-11-16 17:12:58,170 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:58,171 - INFO - Retrying request to /chat/completions in 0.405228 seconds\n",
      "2024-11-16 17:12:58,397 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:12:58,398 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:12:58,399 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:12:58,404 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:58,459 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:58,459 - INFO - Retrying request to /chat/completions in 0.776552 seconds\n",
      "2024-11-16 17:12:58,506 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:12:58,610 - INFO - Progress: 114 samples processed in 0:07:39.991902\n",
      "Processing samples:  56%|█████▌    | 112/200 [07:39<06:27,  4.40s/it]2024-11-16 17:12:58,898 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:58,899 - INFO - Retrying request to /chat/completions in 0.951171 seconds\n",
      "2024-11-16 17:12:59,526 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:12:59,528 - ERROR - Error processing index 110: RetryError[<Future at 0x73f545df2750 state=finished raised RateLimitError>]\n",
      "Processing samples:  56%|█████▋    | 113/200 [07:40<04:52,  3.36s/it]2024-11-16 17:13:00,098 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:00,099 - ERROR - Error processing index 111: RetryError[<Future at 0x73f5445847a0 state=finished raised RateLimitError>]\n",
      "Processing samples:  57%|█████▋    | 114/200 [07:41<03:36,  2.52s/it]2024-11-16 17:13:01,511 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:01,546 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:01,547 - INFO - Retrying request to /chat/completions in 0.484289 seconds\n",
      "2024-11-16 17:13:02,294 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:02,295 - INFO - Retrying request to /chat/completions in 0.798002 seconds\n",
      "2024-11-16 17:13:03,338 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:03,339 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:13:06,745 - INFO - Retrying request to /chat/completions in 0.391017 seconds\n",
      "2024-11-16 17:13:06,766 - INFO - Retrying request to /chat/completions in 0.391363 seconds\n",
      "2024-11-16 17:13:08,427 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:09,469 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:09,612 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:09,613 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:09,614 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:10,262 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:10,264 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:10,264 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:11,237 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:11,239 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:11,239 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:12,061 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:12,063 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:12,064 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:12,172 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:12,174 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:12,174 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:12,181 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:12,272 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:12,276 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:12,277 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:12,294 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:12,295 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:12,371 - INFO - Progress: 115 samples processed in 0:07:53.753212\n",
      "Processing samples:  57%|█████▊    | 115/200 [07:53<07:43,  5.45s/it]2024-11-16 17:13:12,574 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:12,574 - INFO - Retrying request to /chat/completions in 0.378042 seconds\n",
      "2024-11-16 17:13:12,607 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:12,607 - INFO - Retrying request to /chat/completions in 0.489598 seconds\n",
      "2024-11-16 17:13:13,221 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:13,222 - INFO - Retrying request to /chat/completions in 0.882100 seconds\n",
      "2024-11-16 17:13:13,363 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:13,365 - INFO - Retrying request to /chat/completions in 0.772813 seconds\n",
      "2024-11-16 17:13:13,718 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:13,720 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:13,721 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:13,977 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:13,978 - INFO - Retrying request to /chat/completions in 0.486266 seconds\n",
      "2024-11-16 17:13:14,374 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:14,411 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:14,735 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:14,736 - INFO - Retrying request to /chat/completions in 0.773021 seconds\n",
      "2024-11-16 17:13:15,631 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:15,632 - INFO - Retrying request to /chat/completions in 0.487730 seconds\n",
      "2024-11-16 17:13:15,680 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:15,681 - INFO - Retrying request to /chat/completions in 0.449006 seconds\n",
      "2024-11-16 17:13:15,765 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:16,394 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:16,395 - INFO - Retrying request to /chat/completions in 0.803505 seconds\n",
      "2024-11-16 17:13:16,462 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:16,483 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:16,483 - INFO - Retrying request to /chat/completions in 0.987844 seconds\n",
      "2024-11-16 17:13:17,064 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:17,065 - INFO - Retrying request to /chat/completions in 0.482153 seconds\n",
      "2024-11-16 17:13:17,490 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:17,720 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:17,825 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:17,826 - INFO - Retrying request to /chat/completions in 0.940411 seconds\n",
      "2024-11-16 17:13:18,201 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:18,203 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:18,204 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:18,822 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:18,823 - INFO - Retrying request to /chat/completions in 0.425978 seconds\n",
      "2024-11-16 17:13:19,052 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:19,502 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:19,503 - INFO - Retrying request to /chat/completions in 0.973443 seconds\n",
      "2024-11-16 17:13:19,698 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:19,699 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:19,700 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:19,778 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:19,779 - INFO - Retrying request to /chat/completions in 0.375967 seconds\n",
      "2024-11-16 17:13:20,401 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:20,402 - INFO - Retrying request to /chat/completions in 0.834978 seconds\n",
      "2024-11-16 17:13:20,464 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:20,466 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:20,466 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:20,472 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:20,564 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:20,635 - INFO - Progress: 119 samples processed in 0:08:02.017073\n",
      "Processing samples:  58%|█████▊    | 116/200 [08:01<08:48,  6.29s/it]2024-11-16 17:13:20,741 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:20,824 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:20,825 - INFO - Retrying request to /chat/completions in 0.387946 seconds\n",
      "2024-11-16 17:13:21,469 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:21,469 - INFO - Retrying request to /chat/completions in 0.761919 seconds\n",
      "2024-11-16 17:13:21,503 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:22,529 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:23,865 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:23,866 - INFO - Retrying request to /chat/completions in 0.417744 seconds\n",
      "2024-11-16 17:13:24,568 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:24,569 - INFO - Retrying request to /chat/completions in 0.969216 seconds\n",
      "2024-11-16 17:13:24,986 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:25,664 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:25,665 - INFO - Retrying request to /chat/completions in 0.490664 seconds\n",
      "2024-11-16 17:13:25,822 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:13:25,823 - INFO - Retrying request to /chat/completions in 0.430909 seconds\n",
      "2024-11-16 17:13:30,505 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:30,507 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:30,508 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:30,821 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:30,823 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:30,823 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:30,941 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:30,943 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:30,943 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:30,951 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:31,042 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:31,107 - INFO - Progress: 118 samples processed in 0:08:12.489333\n",
      "Processing samples:  58%|█████▊    | 117/200 [08:12<10:26,  7.55s/it]2024-11-16 17:13:31,217 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:31,219 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:31,219 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:31,226 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:31,331 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:31,441 - INFO - Progress: 117 samples processed in 0:08:12.823255\n",
      "Processing samples:  59%|█████▉    | 118/200 [08:12<07:21,  5.38s/it]2024-11-16 17:13:32,779 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:32,781 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:32,782 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:34,671 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:34,673 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:34,674 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:34,684 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:34,764 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:34,843 - INFO - Progress: 120 samples processed in 0:08:16.224914\n",
      "Processing samples:  60%|█████▉    | 119/200 [08:16<06:27,  4.79s/it]2024-11-16 17:13:36,054 - INFO - Retrying request to /chat/completions in 0.401918 seconds\n",
      "2024-11-16 17:13:36,397 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:38,495 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:39,005 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:39,007 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:39,008 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:39,065 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:39,066 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:39,067 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:40,769 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:40,771 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:40,772 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:40,777 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:40,836 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:40,885 - INFO - Progress: 116 samples processed in 0:08:22.267030\n",
      "Processing samples:  60%|██████    | 120/200 [08:22<06:53,  5.16s/it]2024-11-16 17:13:40,981 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:41,001 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:41,003 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:41,004 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:41,094 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:41,096 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:41,097 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:41,654 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:41,656 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:41,657 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:41,663 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:41,881 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:41,913 - INFO - Progress: 122 samples processed in 0:08:23.295161\n",
      "Processing samples:  60%|██████    | 121/200 [08:23<05:09,  3.92s/it]2024-11-16 17:13:43,327 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:43,329 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:43,330 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:43,784 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:43,786 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:43,786 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:45,119 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:45,148 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:45,149 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:45,154 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:45,238 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:45,313 - INFO - Progress: 121 samples processed in 0:08:26.694665\n",
      "2024-11-16 17:13:45,313 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing samples:  61%|██████    | 122/200 [08:26<04:53,  3.77s/it]2024-11-16 17:13:46,340 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:46,893 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:46,895 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:46,896 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:47,790 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:47,792 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:47,793 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:47,908 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:47,910 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:47,910 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:47,915 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:47,998 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:48,096 - INFO - Progress: 123 samples processed in 0:08:29.477994\n",
      "Processing samples:  62%|██████▏   | 123/200 [08:29<04:27,  3.47s/it]2024-11-16 17:13:48,772 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:48,774 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:48,775 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:49,363 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:50,137 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:50,139 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:50,139 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:51,060 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:51,062 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:51,063 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:51,070 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:51,177 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:51,269 - INFO - Progress: 124 samples processed in 0:08:32.651329\n",
      "2024-11-16 17:13:51,271 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing samples:  62%|██████▏   | 124/200 [08:32<04:17,  3.38s/it]2024-11-16 17:13:51,273 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:51,274 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:51,860 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:51,862 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:51,863 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:52,134 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:52,729 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:52,731 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:52,731 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:52,737 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:52,846 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:52,922 - INFO - Progress: 125 samples processed in 0:08:34.303488\n",
      "Processing samples:  62%|██████▎   | 125/200 [08:34<03:34,  2.86s/it]2024-11-16 17:13:55,867 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:55,869 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:13:55,870 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:13:56,817 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:56,819 - INFO - LLMCall function forward\n",
      "2024-11-16 17:13:56,820 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:13:57,987 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:57,989 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:58,989 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:13:58,990 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:13:58,991 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:13:58,998 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:59,091 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:13:59,161 - INFO - Progress: 126 samples processed in 0:08:40.542801\n",
      "Processing samples:  63%|██████▎   | 126/200 [08:40<04:46,  3.88s/it]2024-11-16 17:14:00,783 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:00,785 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:00,786 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:00,799 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:00,800 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:00,801 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:00,898 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:00,900 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:00,901 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:02,825 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:02,827 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:02,828 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:02,833 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:02,911 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:02,982 - INFO - Progress: 127 samples processed in 0:08:44.364167\n",
      "Processing samples:  64%|██████▎   | 127/200 [08:44<04:41,  3.86s/it]2024-11-16 17:14:03,682 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:04,414 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:04,416 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:04,416 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:04,512 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:04,514 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:04,514 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:06,852 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:06,854 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:06,855 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:07,159 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:07,161 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:07,161 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:07,167 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:07,250 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:07,321 - INFO - Progress: 129 samples processed in 0:08:48.703331\n",
      "Processing samples:  64%|██████▍   | 128/200 [08:48<04:48,  4.00s/it]2024-11-16 17:14:07,334 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:07,336 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:07,336 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:07,342 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:07,411 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:07,476 - INFO - Progress: 128 samples processed in 0:08:48.857923\n",
      "Processing samples:  64%|██████▍   | 129/200 [08:48<03:22,  2.85s/it]2024-11-16 17:14:07,987 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:09,301 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:09,303 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:09,304 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:10,414 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:10,416 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:10,416 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:10,481 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:10,482 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:10,483 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:10,488 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:10,565 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:10,687 - INFO - Progress: 130 samples processed in 0:08:52.069433\n",
      "Processing samples:  65%|██████▌   | 130/200 [08:52<03:27,  2.96s/it]2024-11-16 17:14:11,352 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:11,541 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:12,232 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:12,234 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:12,235 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:13,137 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:13,139 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:13,140 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:13,146 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:13,222 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:13,295 - INFO - Progress: 131 samples processed in 0:08:54.677168\n",
      "Processing samples:  66%|██████▌   | 131/200 [08:54<03:16,  2.85s/it]2024-11-16 17:14:13,685 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:13,687 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:13,687 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:13,893 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:13,895 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:13,896 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:14,549 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:16,208 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:16,210 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:16,210 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:16,635 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:16,637 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:16,637 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:17,028 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:17,030 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:17,030 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:17,036 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:17,092 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:17,094 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:17,095 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:17,147 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:17,249 - INFO - Progress: 132 samples processed in 0:08:58.630558\n",
      "Processing samples:  66%|██████▌   | 132/200 [08:58<03:36,  3.18s/it]2024-11-16 17:14:17,526 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:17,647 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:17,648 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:17,649 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:17,656 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:17,749 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:17,834 - INFO - Progress: 133 samples processed in 0:08:59.216469\n",
      "Processing samples:  66%|██████▋   | 133/200 [08:59<02:41,  2.40s/it]2024-11-16 17:14:18,976 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:18,977 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:18,978 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:20,040 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:20,042 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:20,043 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:20,049 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:20,157 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:20,234 - INFO - Progress: 134 samples processed in 0:09:01.616331\n",
      "Processing samples:  67%|██████▋   | 134/200 [09:01<02:38,  2.40s/it]2024-11-16 17:14:21,346 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:22,068 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:22,756 - INFO - Retrying request to /chat/completions in 0.400369 seconds\n",
      "2024-11-16 17:14:23,461 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:23,463 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:23,464 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:23,790 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:23,791 - INFO - Retrying request to /chat/completions in 0.467610 seconds\n",
      "2024-11-16 17:14:24,521 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:24,522 - INFO - Retrying request to /chat/completions in 0.935563 seconds\n",
      "2024-11-16 17:14:24,601 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:24,603 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:24,604 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:24,637 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:24,828 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:24,830 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:24,831 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:24,911 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:24,912 - INFO - Retrying request to /chat/completions in 0.375380 seconds\n",
      "2024-11-16 17:14:24,928 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:24,929 - INFO - Retrying request to /chat/completions in 0.426854 seconds\n",
      "2024-11-16 17:14:25,093 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:25,094 - INFO - Retrying request to /chat/completions in 0.393972 seconds\n",
      "2024-11-16 17:14:25,541 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:25,542 - INFO - Retrying request to /chat/completions in 0.845855 seconds\n",
      "2024-11-16 17:14:25,657 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:25,657 - INFO - Retrying request to /chat/completions in 0.828959 seconds\n",
      "2024-11-16 17:14:25,706 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:27,919 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:27,921 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:27,921 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:27,968 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:27,970 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:27,971 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:28,116 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:28,118 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:28,118 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:28,813 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:28,815 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:28,816 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:29,400 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:29,401 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:29,402 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:29,409 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:29,423 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:29,426 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:29,427 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:29,493 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:29,577 - INFO - Progress: 135 samples processed in 0:09:10.958982\n",
      "Processing samples:  68%|██████▊   | 135/200 [09:10<04:51,  4.48s/it]2024-11-16 17:14:29,743 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:29,745 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:29,745 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:29,751 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:29,828 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:29,915 - INFO - Progress: 137 samples processed in 0:09:11.296559\n",
      "Processing samples:  68%|██████▊   | 136/200 [09:11<03:27,  3.24s/it]2024-11-16 17:14:30,468 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:30,470 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:30,471 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:30,477 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:30,548 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:30,595 - INFO - Progress: 138 samples processed in 0:09:11.977096\n",
      "Processing samples:  68%|██████▊   | 137/200 [09:11<02:35,  2.47s/it]2024-11-16 17:14:30,751 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:30,753 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:30,754 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:30,759 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:30,866 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:31,005 - INFO - Progress: 136 samples processed in 0:09:12.386991\n",
      "Processing samples:  69%|██████▉   | 138/200 [09:12<01:54,  1.85s/it]2024-11-16 17:14:32,497 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:32,498 - INFO - Retrying request to /chat/completions in 0.494325 seconds\n",
      "2024-11-16 17:14:33,244 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:33,245 - INFO - Retrying request to /chat/completions in 0.834867 seconds\n",
      "2024-11-16 17:14:34,074 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:34,328 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:34,329 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:14:34,764 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:35,213 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:36,540 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:36,542 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:36,542 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:36,987 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:36,989 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:36,989 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:37,249 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:37,251 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:37,252 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:38,553 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:38,555 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:38,555 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:38,753 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:38,755 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:38,756 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:39,540 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:39,541 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:39,542 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:39,687 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:39,689 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:39,689 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:39,695 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:39,790 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:39,879 - INFO - Progress: 140 samples processed in 0:09:21.261112\n",
      "Processing samples:  70%|██████▉   | 139/200 [09:21<04:01,  3.96s/it]2024-11-16 17:14:39,880 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:39,883 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:39,883 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:39,891 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:39,984 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:40,060 - INFO - Progress: 142 samples processed in 0:09:21.441703\n",
      "Processing samples:  70%|███████   | 140/200 [09:21<02:49,  2.83s/it]2024-11-16 17:14:40,970 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:40,972 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:40,973 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:40,982 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:41,078 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:41,151 - INFO - Progress: 141 samples processed in 0:09:22.532536\n",
      "Processing samples:  70%|███████   | 141/200 [09:22<02:16,  2.31s/it]2024-11-16 17:14:43,175 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:44,050 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:44,209 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:44,441 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:44,442 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:44,443 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:46,110 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:46,112 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:46,113 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:46,453 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:46,455 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:46,456 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:46,880 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:46,882 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:46,882 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:46,887 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:46,922 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:46,965 - INFO - Progress: 139 samples processed in 0:09:28.346739\n",
      "Processing samples:  71%|███████   | 142/200 [09:28<03:14,  3.36s/it]2024-11-16 17:14:48,210 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:48,211 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:48,212 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:49,025 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:49,027 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:49,028 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:49,033 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:49,093 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:49,096 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:49,155 - INFO - Progress: 143 samples processed in 0:09:30.536802\n",
      "Processing samples:  72%|███████▏  | 143/200 [09:30<02:51,  3.01s/it]2024-11-16 17:14:49,713 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:49,715 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:49,716 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:50,454 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:50,456 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:50,456 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:52,376 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:52,378 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:52,379 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:53,092 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:53,094 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:53,095 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:53,478 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:53,479 - INFO - Retrying request to /chat/completions in 0.454931 seconds\n",
      "2024-11-16 17:14:53,627 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:53,628 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:53,629 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:53,635 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:53,747 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:53,830 - INFO - Progress: 144 samples processed in 0:09:35.211915\n",
      "Processing samples:  72%|███████▏  | 144/200 [09:35<03:16,  3.51s/it]2024-11-16 17:14:54,004 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:54,122 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:54,202 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:54,203 - INFO - Retrying request to /chat/completions in 0.811882 seconds\n",
      "2024-11-16 17:14:55,285 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:56,577 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:56,578 - INFO - Retrying request to /chat/completions in 0.437317 seconds\n",
      "2024-11-16 17:14:56,616 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:56,617 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:56,618 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:56,840 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:56,842 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:56,843 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:57,269 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:57,269 - INFO - Retrying request to /chat/completions in 0.827563 seconds\n",
      "2024-11-16 17:14:58,215 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:58,345 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:58,402 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:58,404 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:58,405 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:58,493 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:58,494 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:14:58,495 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:14:59,460 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:59,462 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:59,463 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:59,469 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:59,526 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:59,528 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:14:59,528 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:14:59,535 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:59,615 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:14:59,616 - INFO - Retrying request to /chat/completions in 0.392475 seconds\n",
      "2024-11-16 17:14:59,622 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:59,743 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:14:59,791 - INFO - Progress: 146 samples processed in 0:09:41.172616\n",
      "Processing samples:  72%|███████▎  | 145/200 [09:41<03:53,  4.24s/it]2024-11-16 17:14:59,823 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:14:59,826 - INFO - LLMCall function forward\n",
      "2024-11-16 17:14:59,827 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:14:59,865 - INFO - Progress: 147 samples processed in 0:09:41.247118\n",
      "2024-11-16 17:15:00,281 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:00,282 - INFO - Retrying request to /chat/completions in 0.937690 seconds\n",
      "2024-11-16 17:15:01,468 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:01,860 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:01,862 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:01,862 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:02,809 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:02,810 - INFO - Retrying request to /chat/completions in 0.424258 seconds\n",
      "2024-11-16 17:15:03,401 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:03,403 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:03,404 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:03,410 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:03,500 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:03,554 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:03,554 - INFO - Retrying request to /chat/completions in 0.822185 seconds\n",
      "2024-11-16 17:15:03,585 - INFO - Progress: 148 samples processed in 0:09:44.967119\n",
      "Processing samples:  74%|███████▎  | 147/200 [09:44<02:47,  3.16s/it]2024-11-16 17:15:04,581 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:04,581 - INFO - Retrying request to /chat/completions in 0.401517 seconds\n",
      "2024-11-16 17:15:04,671 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:04,672 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:15:05,257 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:05,258 - INFO - Retrying request to /chat/completions in 0.777030 seconds\n",
      "2024-11-16 17:15:06,281 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:06,801 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:11,127 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:11,128 - INFO - Retrying request to /chat/completions in 0.484936 seconds\n",
      "2024-11-16 17:15:11,304 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:11,724 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:11,726 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:11,727 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:11,872 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:11,873 - INFO - Retrying request to /chat/completions in 0.935827 seconds\n",
      "2024-11-16 17:15:12,599 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:12,600 - INFO - Retrying request to /chat/completions in 0.482406 seconds\n",
      "2024-11-16 17:15:12,920 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:12,921 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:12,922 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:13,091 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:13,092 - ERROR - Error processing index 144: RetryError[<Future at 0x73f555df39e0 state=finished raised RateLimitError>]\n",
      "Processing samples:  74%|███████▍  | 148/200 [09:54<04:06,  4.73s/it]2024-11-16 17:15:13,332 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:13,333 - INFO - Retrying request to /chat/completions in 0.979109 seconds\n",
      "2024-11-16 17:15:13,766 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:13,768 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:13,769 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:14,563 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:14,564 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:15:14,686 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:14,688 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:14,688 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:14,694 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:14,766 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:14,770 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:14,777 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:14,777 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:14,840 - INFO - Progress: 149 samples processed in 0:09:56.222297\n",
      "Processing samples:  74%|███████▍  | 149/200 [09:56<03:21,  3.95s/it]2024-11-16 17:15:15,722 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:15,723 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:15,724 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:15,730 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:15,811 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:15,882 - INFO - Progress: 151 samples processed in 0:09:57.264163\n",
      "Processing samples:  75%|███████▌  | 150/200 [09:57<02:38,  3.16s/it]2024-11-16 17:15:17,261 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:18,178 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:18,179 - INFO - Retrying request to /chat/completions in 0.375407 seconds\n",
      "2024-11-16 17:15:18,866 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:18,867 - INFO - Retrying request to /chat/completions in 0.436975 seconds\n",
      "2024-11-16 17:15:18,879 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:18,888 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:18,889 - INFO - Retrying request to /chat/completions in 0.922286 seconds\n",
      "2024-11-16 17:15:19,123 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:19,123 - INFO - Retrying request to /chat/completions in 0.383636 seconds\n",
      "2024-11-16 17:15:19,554 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:19,555 - INFO - Retrying request to /chat/completions in 0.923737 seconds\n",
      "2024-11-16 17:15:19,781 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:19,782 - INFO - Retrying request to /chat/completions in 0.780970 seconds\n",
      "2024-11-16 17:15:20,057 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:20,733 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:20,734 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:15:20,832 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:21,378 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:21,379 - INFO - Retrying request to /chat/completions in 0.485909 seconds\n",
      "2024-11-16 17:15:22,078 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:22,078 - INFO - Retrying request to /chat/completions in 0.466012 seconds\n",
      "2024-11-16 17:15:22,107 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:22,108 - INFO - Retrying request to /chat/completions in 0.773953 seconds\n",
      "2024-11-16 17:15:22,844 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:22,844 - INFO - Retrying request to /chat/completions in 0.898038 seconds\n",
      "2024-11-16 17:15:23,124 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:23,995 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:24,402 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:24,403 - INFO - Retrying request to /chat/completions in 0.390866 seconds\n",
      "2024-11-16 17:15:25,077 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:25,078 - INFO - Retrying request to /chat/completions in 0.884770 seconds\n",
      "2024-11-16 17:15:25,338 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:25,339 - INFO - Retrying request to /chat/completions in 0.414752 seconds\n",
      "2024-11-16 17:15:25,612 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:25,612 - INFO - Retrying request to /chat/completions in 0.377972 seconds\n",
      "2024-11-16 17:15:26,038 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:26,039 - INFO - Retrying request to /chat/completions in 0.917717 seconds\n",
      "2024-11-16 17:15:26,213 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:26,288 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:26,288 - INFO - Retrying request to /chat/completions in 0.888325 seconds\n",
      "2024-11-16 17:15:28,697 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:28,698 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:28,699 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:28,715 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:29,216 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:30,695 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:30,697 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:30,697 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:31,067 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:31,069 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:31,070 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:31,087 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:31,089 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:31,089 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:31,878 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:31,880 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:31,881 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:34,650 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:34,651 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:34,652 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:34,658 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:34,736 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:34,818 - INFO - Progress: 153 samples processed in 0:10:16.200189\n",
      "Processing samples:  76%|███████▌  | 151/200 [10:16<06:11,  7.58s/it]2024-11-16 17:15:35,218 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:35,220 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:35,221 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:35,788 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:35,790 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:35,790 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:35,963 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:35,965 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:35,965 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:37,358 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:37,360 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:37,361 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:37,367 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:37,458 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:37,531 - INFO - Progress: 152 samples processed in 0:10:18.913464\n",
      "Processing samples:  76%|███████▌  | 152/200 [10:18<04:56,  6.19s/it]2024-11-16 17:15:37,646 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:37,647 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:37,648 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:37,655 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:37,734 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:37,770 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:37,772 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:37,773 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:37,778 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:37,858 - INFO - Progress: 154 samples processed in 0:10:19.240305\n",
      "Processing samples:  76%|███████▋  | 153/200 [10:19<03:30,  4.49s/it]2024-11-16 17:15:37,913 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:37,979 - INFO - Progress: 150 samples processed in 0:10:19.360536\n",
      "Processing samples:  77%|███████▋  | 154/200 [10:19<02:27,  3.21s/it]2024-11-16 17:15:39,367 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:42,651 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:42,652 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:42,653 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:43,637 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:43,819 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:45,314 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:45,316 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:45,316 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:45,584 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:45,586 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:45,586 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:45,865 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:45,865 - INFO - Retrying request to /chat/completions in 0.479917 seconds\n",
      "2024-11-16 17:15:46,599 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:46,602 - INFO - Retrying request to /chat/completions in 0.814145 seconds\n",
      "2024-11-16 17:15:47,035 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:47,037 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:47,037 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:47,043 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:47,128 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:47,207 - INFO - Progress: 155 samples processed in 0:10:28.588728\n",
      "Processing samples:  78%|███████▊  | 155/200 [10:28<03:44,  4.98s/it]2024-11-16 17:15:47,389 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:47,597 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:47,599 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:47,599 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:47,667 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:48,921 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:48,922 - INFO - Retrying request to /chat/completions in 0.446023 seconds\n",
      "2024-11-16 17:15:49,670 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:49,671 - INFO - Retrying request to /chat/completions in 0.853393 seconds\n",
      "2024-11-16 17:15:49,771 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:49,773 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:49,774 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:50,138 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:50,140 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:50,140 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:50,513 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:50,513 - INFO - Retrying request to /chat/completions in 0.430430 seconds\n",
      "2024-11-16 17:15:50,817 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:51,132 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:51,209 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:51,209 - INFO - Retrying request to /chat/completions in 0.822463 seconds\n",
      "2024-11-16 17:15:51,819 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:51,821 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:51,821 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:52,374 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:52,414 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:52,415 - INFO - Retrying request to /chat/completions in 0.397845 seconds\n",
      "2024-11-16 17:15:53,038 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:53,040 - INFO - LLMCall function forward\n",
      "2024-11-16 17:15:53,041 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:15:53,134 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:53,135 - INFO - Retrying request to /chat/completions in 0.833422 seconds\n",
      "2024-11-16 17:15:53,642 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:53,643 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:53,644 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:53,650 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:53,660 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:53,661 - INFO - Retrying request to /chat/completions in 0.479713 seconds\n",
      "2024-11-16 17:15:53,755 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:53,874 - INFO - Progress: 157 samples processed in 0:10:35.255528\n",
      "Processing samples:  78%|███████▊  | 156/200 [10:35<04:01,  5.48s/it]2024-11-16 17:15:54,242 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:54,561 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:54,561 - INFO - Retrying request to /chat/completions in 0.969858 seconds\n",
      "2024-11-16 17:15:55,368 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:55,370 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:15:55,371 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:15:55,786 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:57,176 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:15:57,178 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:15:57,178 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:15:57,184 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:57,248 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:15:57,305 - INFO - Progress: 159 samples processed in 0:10:38.686506\n",
      "Processing samples:  78%|███████▊  | 157/200 [10:38<03:29,  4.87s/it]2024-11-16 17:15:57,375 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:57,375 - INFO - Retrying request to /chat/completions in 0.396937 seconds\n",
      "2024-11-16 17:15:58,110 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:58,111 - INFO - Retrying request to /chat/completions in 0.392343 seconds\n",
      "2024-11-16 17:15:58,121 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:58,122 - INFO - Retrying request to /chat/completions in 0.944862 seconds\n",
      "2024-11-16 17:15:58,800 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:58,801 - INFO - Retrying request to /chat/completions in 0.961392 seconds\n",
      "2024-11-16 17:15:59,340 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:15:59,900 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:00,030 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:02,338 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:02,982 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:02,983 - INFO - Retrying request to /chat/completions in 0.465275 seconds\n",
      "2024-11-16 17:16:03,013 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:03,015 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:03,016 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:03,598 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:03,598 - INFO - Retrying request to /chat/completions in 0.409433 seconds\n",
      "2024-11-16 17:16:04,260 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:04,262 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:04,263 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:04,454 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:04,455 - INFO - Retrying request to /chat/completions in 0.819568 seconds\n",
      "2024-11-16 17:16:05,581 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:05,696 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:05,698 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:05,698 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:06,661 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:06,663 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:06,664 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:07,807 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:07,809 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:16:07,810 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:16:07,816 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:07,888 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:07,966 - INFO - Progress: 160 samples processed in 0:10:49.347551\n",
      "Processing samples:  79%|███████▉  | 158/200 [10:49<04:37,  6.60s/it]2024-11-16 17:16:08,247 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:08,248 - INFO - Retrying request to /chat/completions in 0.932401 seconds\n",
      "2024-11-16 17:16:08,251 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:08,253 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:16:08,254 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:16:08,265 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:08,383 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:08,469 - INFO - Progress: 161 samples processed in 0:10:49.851299\n",
      "Processing samples:  80%|███████▉  | 159/200 [10:49<03:15,  4.78s/it]2024-11-16 17:16:09,437 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:09,439 - ERROR - Error processing index 157: RetryError[<Future at 0x73f5448390a0 state=finished raised RateLimitError>]\n",
      "Processing samples:  80%|████████  | 160/200 [10:50<02:25,  3.64s/it]2024-11-16 17:16:10,458 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:10,459 - INFO - Retrying request to /chat/completions in 0.485402 seconds\n",
      "2024-11-16 17:16:10,909 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:10,910 - INFO - Retrying request to /chat/completions in 0.494376 seconds\n",
      "2024-11-16 17:16:11,203 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:11,204 - INFO - Retrying request to /chat/completions in 0.796317 seconds\n",
      "2024-11-16 17:16:11,676 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:11,678 - INFO - Retrying request to /chat/completions in 0.881016 seconds\n",
      "2024-11-16 17:16:12,264 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:12,265 - ERROR - Error processing index 155: RetryError[<Future at 0x73f5194f2cf0 state=finished raised RateLimitError>]\n",
      "Processing samples:  80%|████████  | 161/200 [10:53<02:12,  3.40s/it]2024-11-16 17:16:12,624 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:12,812 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:12,814 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:16:13,800 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:14,948 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:14,950 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:14,951 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:16,364 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:16,365 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:16,366 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:16,599 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:16,601 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:16,602 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:16,769 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:17,487 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:17,489 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:16:17,489 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:16:17,496 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:17,717 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:17,785 - INFO - Progress: 163 samples processed in 0:10:59.167004\n",
      "Processing samples:  81%|████████  | 162/200 [10:59<02:33,  4.03s/it]2024-11-16 17:16:18,195 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:18,197 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:18,198 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:18,654 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:18,656 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:18,657 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:19,120 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:19,122 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:16:19,122 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:16:19,129 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:19,206 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:19,270 - INFO - Progress: 164 samples processed in 0:11:00.651591\n",
      "Processing samples:  82%|████████▏ | 163/200 [11:00<02:00,  3.27s/it]2024-11-16 17:16:19,615 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:19,616 - INFO - Retrying request to /chat/completions in 0.478560 seconds\n",
      "2024-11-16 17:16:20,061 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:20,062 - INFO - Retrying request to /chat/completions in 0.467686 seconds\n",
      "2024-11-16 17:16:20,554 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:20,555 - INFO - Retrying request to /chat/completions in 0.924719 seconds\n",
      "2024-11-16 17:16:20,836 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:20,837 - INFO - Retrying request to /chat/completions in 0.458663 seconds\n",
      "2024-11-16 17:16:21,549 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:21,550 - INFO - Retrying request to /chat/completions in 0.782086 seconds\n",
      "2024-11-16 17:16:21,736 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:21,963 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:21,964 - INFO - Retrying request to /chat/completions in 0.997194 seconds\n",
      "2024-11-16 17:16:22,631 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:22,632 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:16:22,986 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:22,987 - INFO - Retrying request to /chat/completions in 0.391365 seconds\n",
      "2024-11-16 17:16:23,208 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:23,209 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:16:23,657 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:23,658 - INFO - Retrying request to /chat/completions in 0.941696 seconds\n",
      "2024-11-16 17:16:23,745 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:24,855 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:25,529 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:25,531 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:25,531 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:26,526 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:26,527 - INFO - Retrying request to /chat/completions in 0.420279 seconds\n",
      "2024-11-16 17:16:27,486 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:27,488 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:27,488 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:28,305 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:28,307 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:16:28,307 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:16:28,314 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:28,397 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:28,475 - INFO - Progress: 167 samples processed in 0:11:09.857416\n",
      "Processing samples:  82%|████████▏ | 164/200 [11:09<03:01,  5.05s/it]2024-11-16 17:16:28,710 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:28,712 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:28,713 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:30,680 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:30,681 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:16:30,682 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:16:30,688 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:30,781 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:16:30,864 - INFO - Progress: 165 samples processed in 0:11:12.246051\n",
      "Processing samples:  82%|████████▎ | 165/200 [11:12<02:28,  4.25s/it]2024-11-16 17:16:31,326 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:31,580 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:31,732 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:33,122 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:33,124 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:33,125 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:33,393 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:33,395 - INFO - LLMCall function forward\n",
      "2024-11-16 17:16:33,396 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:16:33,812 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:33,812 - INFO - Retrying request to /chat/completions in 0.464669 seconds\n",
      "2024-11-16 17:16:34,586 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:34,587 - INFO - Retrying request to /chat/completions in 0.793212 seconds\n",
      "2024-11-16 17:16:34,702 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:34,703 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:34,704 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:34,958 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:34,958 - INFO - Retrying request to /chat/completions in 0.394046 seconds\n",
      "2024-11-16 17:16:35,165 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:35,167 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:16:35,167 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:16:35,419 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:35,420 - INFO - Retrying request to /chat/completions in 0.448528 seconds\n",
      "2024-11-16 17:16:35,678 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:35,679 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:16:35,717 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:35,718 - INFO - Retrying request to /chat/completions in 0.757222 seconds\n",
      "2024-11-16 17:16:36,119 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:36,120 - INFO - Retrying request to /chat/completions in 0.796851 seconds\n",
      "2024-11-16 17:16:36,431 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:36,432 - INFO - Retrying request to /chat/completions in 0.455219 seconds\n",
      "2024-11-16 17:16:36,791 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:37,155 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:37,157 - INFO - Retrying request to /chat/completions in 0.783808 seconds\n",
      "2024-11-16 17:16:37,164 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:38,080 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:38,081 - INFO - Retrying request to /chat/completions in 0.389935 seconds\n",
      "2024-11-16 17:16:38,188 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:38,415 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:38,416 - INFO - Retrying request to /chat/completions in 0.493998 seconds\n",
      "2024-11-16 17:16:38,725 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:38,726 - INFO - Retrying request to /chat/completions in 0.752753 seconds\n",
      "2024-11-16 17:16:39,198 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:39,199 - INFO - Retrying request to /chat/completions in 0.859537 seconds\n",
      "2024-11-16 17:16:39,438 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:39,439 - INFO - Retrying request to /chat/completions in 0.411035 seconds\n",
      "2024-11-16 17:16:39,735 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:40,116 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:40,117 - INFO - Retrying request to /chat/completions in 0.775967 seconds\n",
      "2024-11-16 17:16:40,331 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:41,168 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:41,798 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:41,799 - INFO - Retrying request to /chat/completions in 0.447181 seconds\n",
      "2024-11-16 17:16:42,054 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:42,055 - INFO - Retrying request to /chat/completions in 0.393068 seconds\n",
      "2024-11-16 17:16:42,526 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:42,527 - INFO - Retrying request to /chat/completions in 0.870665 seconds\n",
      "2024-11-16 17:16:42,665 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:42,665 - INFO - Retrying request to /chat/completions in 0.483798 seconds\n",
      "2024-11-16 17:16:42,931 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:42,932 - INFO - Retrying request to /chat/completions in 0.436355 seconds\n",
      "2024-11-16 17:16:43,361 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:43,362 - INFO - Retrying request to /chat/completions in 0.799440 seconds\n",
      "2024-11-16 17:16:43,417 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:43,417 - INFO - Retrying request to /chat/completions in 0.933266 seconds\n",
      "2024-11-16 17:16:43,682 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:43,683 - INFO - Retrying request to /chat/completions in 0.938780 seconds\n",
      "2024-11-16 17:16:43,706 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:44,436 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:44,603 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:44,873 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:44,874 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:16:47,084 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:47,084 - INFO - Retrying request to /chat/completions in 0.395171 seconds\n",
      "2024-11-16 17:16:47,093 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:47,093 - INFO - Retrying request to /chat/completions in 0.424925 seconds\n",
      "2024-11-16 17:16:47,726 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:47,727 - INFO - Retrying request to /chat/completions in 0.886769 seconds\n",
      "2024-11-16 17:16:47,796 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:47,797 - INFO - Retrying request to /chat/completions in 0.849515 seconds\n",
      "2024-11-16 17:16:48,095 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:48,095 - INFO - Retrying request to /chat/completions in 0.415832 seconds\n",
      "2024-11-16 17:16:48,796 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:48,797 - INFO - Retrying request to /chat/completions in 0.773012 seconds\n",
      "2024-11-16 17:16:48,861 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:48,937 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:49,886 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:51,091 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:51,092 - INFO - Retrying request to /chat/completions in 0.414978 seconds\n",
      "2024-11-16 17:16:51,796 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:51,796 - INFO - Retrying request to /chat/completions in 0.792881 seconds\n",
      "2024-11-16 17:16:51,987 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:51,988 - INFO - Retrying request to /chat/completions in 0.403705 seconds\n",
      "2024-11-16 17:16:52,116 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:52,117 - INFO - Retrying request to /chat/completions in 0.488583 seconds\n",
      "2024-11-16 17:16:52,689 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:52,689 - INFO - Retrying request to /chat/completions in 0.871292 seconds\n",
      "2024-11-16 17:16:52,883 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:52,884 - ERROR - Error processing index 161: RetryError[<Future at 0x73f5199edf40 state=finished raised RateLimitError>]\n",
      "Processing samples:  83%|████████▎ | 166/200 [11:34<05:25,  9.58s/it]2024-11-16 17:16:52,890 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:52,892 - INFO - Retrying request to /chat/completions in 0.944513 seconds\n",
      "2024-11-16 17:16:53,382 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:53,383 - INFO - Retrying request to /chat/completions in 0.386198 seconds\n",
      "2024-11-16 17:16:53,830 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:53,831 - ERROR - Error processing index 165: RetryError[<Future at 0x73f545ddd940 state=finished raised RateLimitError>]\n",
      "Processing samples:  84%|████████▎ | 167/200 [11:35<03:50,  6.99s/it]2024-11-16 17:16:54,057 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:54,058 - INFO - Retrying request to /chat/completions in 0.893691 seconds\n",
      "2024-11-16 17:16:54,125 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:54,126 - WARNING - Attempt 3 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:16:54,127 - ERROR - All retry attempts failed for GPT response.\n",
      "2024-11-16 17:16:54,127 - ERROR - GPT response for index 168 is empty.\n",
      "Processing samples:  84%|████████▍ | 168/200 [11:35<02:39,  4.98s/it]2024-11-16 17:16:55,275 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:55,276 - ERROR - Error processing index 167: RetryError[<Future at 0x73f519ad6930 state=finished raised RateLimitError>]\n",
      "Processing samples:  84%|████████▍ | 169/200 [11:36<01:58,  3.83s/it]2024-11-16 17:16:56,867 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:57,765 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:57,766 - INFO - Retrying request to /chat/completions in 0.476296 seconds\n",
      "2024-11-16 17:16:57,982 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:57,998 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:16:58,208 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:58,208 - INFO - Retrying request to /chat/completions in 0.398592 seconds\n",
      "2024-11-16 17:16:58,233 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:58,233 - INFO - Retrying request to /chat/completions in 0.438192 seconds\n",
      "2024-11-16 17:16:58,512 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:58,513 - INFO - Retrying request to /chat/completions in 0.880467 seconds\n",
      "2024-11-16 17:16:58,877 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:58,878 - INFO - Retrying request to /chat/completions in 0.976200 seconds\n",
      "2024-11-16 17:16:58,950 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:58,951 - INFO - Retrying request to /chat/completions in 0.445831 seconds\n",
      "2024-11-16 17:16:58,955 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:58,955 - INFO - Retrying request to /chat/completions in 0.973851 seconds\n",
      "2024-11-16 17:16:59,647 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:59,661 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:16:59,661 - INFO - Retrying request to /chat/completions in 0.943386 seconds\n",
      "2024-11-16 17:17:00,102 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:00,103 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:17:00,184 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:02,435 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:02,436 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:02,437 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:02,473 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:02,474 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:02,475 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:03,072 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:03,074 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:03,075 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:04,366 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:04,368 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:04,368 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:04,520 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:04,522 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:04,522 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:04,820 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:04,822 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:04,822 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:05,405 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:05,406 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:05,407 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:05,413 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:05,484 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:05,562 - INFO - Progress: 170 samples processed in 0:11:46.944312\n",
      "Processing samples:  85%|████████▌ | 170/200 [11:46<02:53,  5.77s/it]2024-11-16 17:17:05,714 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:05,715 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:05,716 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:05,722 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:05,800 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:05,868 - INFO - Progress: 171 samples processed in 0:11:47.249505\n",
      "Processing samples:  86%|████████▌ | 171/200 [11:47<01:59,  4.13s/it]2024-11-16 17:17:06,548 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:06,550 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:06,550 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:06,556 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:06,641 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:06,747 - INFO - Progress: 172 samples processed in 0:11:48.128727\n",
      "Processing samples:  86%|████████▌ | 172/200 [11:48<01:28,  3.15s/it]2024-11-16 17:17:08,693 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:10,159 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:10,946 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:12,399 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:12,401 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:12,402 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:12,805 - INFO - Retrying request to /chat/completions in 0.378801 seconds\n",
      "2024-11-16 17:17:13,917 - INFO - Retrying request to /chat/completions in 0.386204 seconds\n",
      "2024-11-16 17:17:14,084 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:14,086 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:14,086 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:15,209 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:15,230 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:15,230 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:15,236 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:15,313 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:15,379 - INFO - Progress: 176 samples processed in 0:11:56.760802\n",
      "Processing samples:  86%|████████▋ | 173/200 [11:56<02:09,  4.80s/it]2024-11-16 17:17:16,174 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:16,681 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:16,683 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:16,684 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:16,719 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:16,721 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:16,721 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:21,407 - INFO - Retrying request to /chat/completions in 0.492300 seconds\n",
      "2024-11-16 17:17:22,601 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:23,376 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:23,378 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:23,379 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:23,569 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:23,571 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:23,572 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:23,954 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:23,956 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:23,957 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:25,373 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:25,375 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:25,376 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:26,210 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:26,212 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:26,213 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:26,219 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:26,312 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:26,389 - INFO - Progress: 175 samples processed in 0:12:07.770597\n",
      "Processing samples:  87%|████████▋ | 174/200 [12:07<02:53,  6.66s/it]2024-11-16 17:17:26,431 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:26,433 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:26,433 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:26,439 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:26,540 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:26,619 - INFO - Progress: 177 samples processed in 0:12:08.001246\n",
      "Processing samples:  88%|████████▊ | 175/200 [12:07<01:58,  4.73s/it]2024-11-16 17:17:27,513 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:27,514 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:27,515 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:27,521 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:27,595 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:27,680 - INFO - Progress: 173 samples processed in 0:12:09.061741\n",
      "Processing samples:  88%|████████▊ | 176/200 [12:09<01:27,  3.63s/it]2024-11-16 17:17:28,644 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:28,647 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:28,647 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:30,888 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:31,177 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:31,650 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:31,652 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:31,653 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:32,587 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:36,197 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:36,199 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:36,200 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:36,206 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:36,295 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:36,390 - INFO - Progress: 174 samples processed in 0:12:17.772213\n",
      "Processing samples:  88%|████████▊ | 177/200 [12:17<01:58,  5.15s/it]2024-11-16 17:17:36,888 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:36,890 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:36,891 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:36,918 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:36,920 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:36,921 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:37,027 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:37,029 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:37,030 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:38,018 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:38,019 - INFO - Retrying request to /chat/completions in 0.435474 seconds\n",
      "2024-11-16 17:17:38,807 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:38,808 - INFO - Retrying request to /chat/completions in 0.498526 seconds\n",
      "2024-11-16 17:17:39,351 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:39,351 - INFO - Retrying request to /chat/completions in 0.898633 seconds\n",
      "2024-11-16 17:17:39,561 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:39,561 - INFO - Retrying request to /chat/completions in 0.755715 seconds\n",
      "2024-11-16 17:17:40,567 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:40,602 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:40,603 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:40,604 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:40,618 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:40,619 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:17:41,475 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:41,477 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:41,477 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:41,828 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:41,829 - INFO - Retrying request to /chat/completions in 0.438245 seconds\n",
      "2024-11-16 17:17:42,529 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:42,530 - INFO - Retrying request to /chat/completions in 0.999212 seconds\n",
      "2024-11-16 17:17:43,186 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:43,188 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:43,189 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:43,194 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:43,271 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:43,343 - INFO - Progress: 180 samples processed in 0:12:24.725137\n",
      "Processing samples:  89%|████████▉ | 178/200 [12:24<02:05,  5.69s/it]2024-11-16 17:17:43,448 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:43,450 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:43,451 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:43,457 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:43,541 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:43,627 - INFO - Progress: 179 samples processed in 0:12:25.008460\n",
      "Processing samples:  90%|████████▉ | 179/200 [12:24<01:25,  4.07s/it]2024-11-16 17:17:43,814 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:45,680 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:45,682 - INFO - Retrying request to /chat/completions in 0.499326 seconds\n",
      "2024-11-16 17:17:46,433 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:46,434 - INFO - Retrying request to /chat/completions in 0.987178 seconds\n",
      "2024-11-16 17:17:47,703 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:48,548 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:48,549 - INFO - Retrying request to /chat/completions in 0.430961 seconds\n",
      "2024-11-16 17:17:49,252 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:49,253 - INFO - Retrying request to /chat/completions in 0.976365 seconds\n",
      "2024-11-16 17:17:49,417 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:49,661 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:49,973 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:49,974 - INFO - Retrying request to /chat/completions in 0.448644 seconds\n",
      "2024-11-16 17:17:50,552 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:50,553 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:17:50,703 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:50,704 - INFO - Retrying request to /chat/completions in 0.905585 seconds\n",
      "2024-11-16 17:17:51,573 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:51,574 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:51,575 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:51,868 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:52,102 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:52,104 - INFO - LLMCall function forward\n",
      "2024-11-16 17:17:52,105 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:17:53,715 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:53,717 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:53,718 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:54,457 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:54,458 - INFO - Retrying request to /chat/completions in 0.444987 seconds\n",
      "2024-11-16 17:17:54,478 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:54,479 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:17:54,480 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:17:55,215 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:55,216 - INFO - Retrying request to /chat/completions in 0.955879 seconds\n",
      "2024-11-16 17:17:56,469 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:56,470 - ERROR - Error processing index 177: RetryError[<Future at 0x73f519a3bd70 state=finished raised RateLimitError>]\n",
      "Processing samples:  90%|█████████ | 180/200 [12:37<02:14,  6.70s/it]2024-11-16 17:17:56,952 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:56,954 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:56,954 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:56,960 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:57,053 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:57,104 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:17:57,106 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:17:57,107 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:17:57,113 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:57,205 - INFO - Progress: 182 samples processed in 0:12:38.587070\n",
      "Processing samples:  90%|█████████ | 181/200 [12:38<01:33,  4.91s/it]2024-11-16 17:17:57,258 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:17:57,338 - INFO - Progress: 183 samples processed in 0:12:38.719579\n",
      "Processing samples:  91%|█████████ | 182/200 [12:38<01:02,  3.48s/it]2024-11-16 17:17:57,901 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:57,902 - INFO - Retrying request to /chat/completions in 0.418378 seconds\n",
      "2024-11-16 17:17:58,589 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:58,590 - INFO - Retrying request to /chat/completions in 0.955760 seconds\n",
      "2024-11-16 17:17:59,969 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:17:59,970 - WARNING - Attempt 3 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:17:59,971 - ERROR - All retry attempts failed for GPT response.\n",
      "2024-11-16 17:17:59,971 - ERROR - GPT response for index 180 is empty.\n",
      "Processing samples:  92%|█████████▏| 183/200 [12:41<00:54,  3.23s/it]2024-11-16 17:18:01,494 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:04,597 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:04,598 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:04,599 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:05,044 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:05,046 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:05,061 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:08,172 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:08,174 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:08,174 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:08,908 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:08,910 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:08,911 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:08,963 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:08,965 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:08,965 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:09,133 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:09,135 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:09,135 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:09,140 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:09,197 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:09,220 - INFO - Progress: 184 samples processed in 0:12:50.601507\n",
      "Processing samples:  92%|█████████▏| 184/200 [12:50<01:20,  5.03s/it]2024-11-16 17:18:09,763 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:09,765 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:09,766 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:11,741 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:11,743 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:11,744 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:11,852 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:11,854 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:11,854 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:13,032 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:13,034 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:13,034 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:13,174 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:13,175 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:13,176 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:13,181 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:13,275 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:13,372 - INFO - Progress: 185 samples processed in 0:12:54.754336\n",
      "Processing samples:  92%|█████████▎| 185/200 [12:54<01:11,  4.77s/it]2024-11-16 17:18:13,660 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:13,662 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:13,663 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:13,668 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:13,750 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:13,757 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:13,855 - INFO - Progress: 187 samples processed in 0:12:55.236719\n",
      "Processing samples:  93%|█████████▎| 186/200 [12:55<00:48,  3.48s/it]2024-11-16 17:18:13,869 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:13,871 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:13,871 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:13,876 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:13,965 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:14,055 - INFO - Progress: 186 samples processed in 0:12:55.437332\n",
      "Processing samples:  94%|█████████▎| 187/200 [12:55<00:32,  2.50s/it]2024-11-16 17:18:16,457 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:16,459 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:16,459 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:17,632 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:18,032 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:18,371 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:18,744 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:18,746 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:18,746 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:19,514 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:19,516 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:19,516 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:19,816 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:19,818 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:19,819 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:19,841 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:19,842 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:19,843 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:19,848 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:19,921 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:20,001 - INFO - Progress: 188 samples processed in 0:13:01.382550\n",
      "Processing samples:  94%|█████████▍| 188/200 [13:01<00:42,  3.53s/it]2024-11-16 17:18:20,197 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:20,199 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:20,200 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:21,175 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:21,177 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:21,177 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:21,576 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:21,578 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:21,579 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:22,210 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:22,211 - INFO - Retrying request to /chat/completions in 0.389809 seconds\n",
      "2024-11-16 17:18:22,418 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:22,420 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:22,420 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:22,426 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:22,516 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:22,614 - INFO - Progress: 189 samples processed in 0:13:03.995845\n",
      "Processing samples:  94%|█████████▍| 189/200 [13:03<00:35,  3.26s/it]2024-11-16 17:18:22,860 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:22,861 - INFO - Retrying request to /chat/completions in 0.910650 seconds\n",
      "2024-11-16 17:18:22,984 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:22,986 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:22,987 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:23,353 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:23,353 - INFO - Retrying request to /chat/completions in 0.461829 seconds\n",
      "2024-11-16 17:18:23,991 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:24,034 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:24,079 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:24,079 - INFO - Retrying request to /chat/completions in 0.864420 seconds\n",
      "2024-11-16 17:18:25,221 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:25,304 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:25,305 - INFO - Retrying request to /chat/completions in 0.422007 seconds\n",
      "2024-11-16 17:18:26,022 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:26,022 - INFO - Retrying request to /chat/completions in 0.798117 seconds\n",
      "2024-11-16 17:18:26,475 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:26,476 - INFO - Retrying request to /chat/completions in 0.484163 seconds\n",
      "2024-11-16 17:18:26,538 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:26,539 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:26,540 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:27,075 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:27,246 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:27,247 - INFO - Retrying request to /chat/completions in 0.826831 seconds\n",
      "2024-11-16 17:18:27,428 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:28,332 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:28,477 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:28,478 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:28,479 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:28,776 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:28,777 - INFO - Retrying request to /chat/completions in 0.469976 seconds\n",
      "2024-11-16 17:18:29,035 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:29,037 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:29,038 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:29,450 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:29,452 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:29,452 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:29,458 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:29,526 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:29,584 - INFO - Progress: 192 samples processed in 0:13:10.965812\n",
      "2024-11-16 17:18:29,584 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "Processing samples:  95%|█████████▌| 190/200 [13:10<00:43,  4.37s/it]2024-11-16 17:18:29,586 - INFO - Retrying request to /chat/completions in 0.768914 seconds\n",
      "2024-11-16 17:18:29,707 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:29,707 - INFO - Retrying request to /chat/completions in 0.385058 seconds\n",
      "2024-11-16 17:18:30,390 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:30,392 - INFO - Retrying request to /chat/completions in 0.775319 seconds\n",
      "2024-11-16 17:18:30,624 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:30,760 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:30,762 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:30,763 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:31,446 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:31,943 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:31,945 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:31,945 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:31,951 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:32,024 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:32,127 - INFO - Progress: 193 samples processed in 0:13:13.508718\n",
      "Processing samples:  96%|█████████▌| 191/200 [13:13<00:34,  3.82s/it]2024-11-16 17:18:33,606 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:34,297 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:34,298 - INFO - Retrying request to /chat/completions in 0.481637 seconds\n",
      "2024-11-16 17:18:34,544 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:34,545 - INFO - Retrying request to /chat/completions in 0.409785 seconds\n",
      "2024-11-16 17:18:35,073 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:35,073 - INFO - Retrying request to /chat/completions in 0.418506 seconds\n",
      "2024-11-16 17:18:35,077 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:35,077 - INFO - Retrying request to /chat/completions in 0.976914 seconds\n",
      "2024-11-16 17:18:35,236 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:35,237 - INFO - Retrying request to /chat/completions in 0.901649 seconds\n",
      "2024-11-16 17:18:35,264 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:35,265 - INFO - Retrying request to /chat/completions in 0.450208 seconds\n",
      "2024-11-16 17:18:35,764 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:35,765 - INFO - Retrying request to /chat/completions in 0.881532 seconds\n",
      "2024-11-16 17:18:35,965 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:35,966 - INFO - Retrying request to /chat/completions in 0.777087 seconds\n",
      "2024-11-16 17:18:36,308 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:36,406 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:36,947 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:36,948 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:18:37,004 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:37,657 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:37,658 - INFO - Retrying request to /chat/completions in 0.469851 seconds\n",
      "2024-11-16 17:18:38,397 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:38,397 - INFO - Retrying request to /chat/completions in 0.965710 seconds\n",
      "2024-11-16 17:18:38,620 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:38,621 - INFO - Retrying request to /chat/completions in 0.422285 seconds\n",
      "2024-11-16 17:18:39,288 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:39,289 - INFO - Retrying request to /chat/completions in 0.776019 seconds\n",
      "2024-11-16 17:18:39,543 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:39,544 - INFO - Retrying request to /chat/completions in 0.434786 seconds\n",
      "2024-11-16 17:18:39,655 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:40,287 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:40,288 - INFO - Retrying request to /chat/completions in 0.916409 seconds\n",
      "2024-11-16 17:18:40,314 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:40,315 - ERROR - Error processing index 190: RetryError[<Future at 0x73f54482deb0 state=finished raised RateLimitError>]\n",
      "Processing samples:  96%|█████████▌| 192/200 [13:21<00:41,  5.13s/it]2024-11-16 17:18:41,298 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:41,299 - INFO - Retrying request to /chat/completions in 0.379367 seconds\n",
      "2024-11-16 17:18:41,488 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:41,489 - ERROR - Error processing index 189: RetryError[<Future at 0x73f544807530 state=finished raised RateLimitError>]\n",
      "Processing samples:  96%|█████████▋| 193/200 [13:22<00:27,  3.94s/it]2024-11-16 17:18:41,927 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:41,927 - INFO - Retrying request to /chat/completions in 0.750588 seconds\n",
      "2024-11-16 17:18:42,940 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:44,201 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:44,201 - INFO - Retrying request to /chat/completions in 0.417699 seconds\n",
      "2024-11-16 17:18:44,860 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:44,861 - INFO - Retrying request to /chat/completions in 0.808322 seconds\n",
      "2024-11-16 17:18:45,019 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:45,020 - INFO - Retrying request to /chat/completions in 0.449844 seconds\n",
      "2024-11-16 17:18:45,717 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:45,718 - INFO - Retrying request to /chat/completions in 0.994011 seconds\n",
      "2024-11-16 17:18:45,941 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:45,942 - WARNING - Attempt 2 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:18:46,968 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:48,264 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:48,265 - INFO - Retrying request to /chat/completions in 0.394557 seconds\n",
      "2024-11-16 17:18:48,394 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:48,457 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:48,963 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:48,963 - INFO - Retrying request to /chat/completions in 0.962651 seconds\n",
      "2024-11-16 17:18:49,982 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:49,984 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:49,985 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:50,175 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:50,176 - ERROR - Error processing index 193: RetryError[<Future at 0x73f5446ca1b0 state=finished raised RateLimitError>]\n",
      "Processing samples:  97%|█████████▋| 194/200 [13:31<00:32,  5.37s/it]2024-11-16 17:18:51,008 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:51,010 - INFO - LLMCall function forward\n",
      "2024-11-16 17:18:51,011 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:18:51,738 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:51,740 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:51,741 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:53,117 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:53,119 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:53,119 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:53,125 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:53,223 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:53,228 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:53,229 - INFO - Retrying request to /chat/completions in 0.462929 seconds\n",
      "2024-11-16 17:18:53,335 - INFO - Progress: 197 samples processed in 0:13:34.717067\n",
      "Processing samples:  98%|█████████▊| 195/200 [13:34<00:23,  4.70s/it]2024-11-16 17:18:53,364 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:53,366 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:18:53,367 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:18:53,970 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:53,971 - INFO - Retrying request to /chat/completions in 0.942814 seconds\n",
      "2024-11-16 17:18:54,848 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:55,155 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:55,156 - WARNING - Attempt 3 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:18:55,156 - ERROR - All retry attempts failed for GPT response.\n",
      "2024-11-16 17:18:55,157 - ERROR - GPT response for index 194 is empty.\n",
      "Processing samples:  98%|█████████▊| 196/200 [13:36<00:15,  3.84s/it]2024-11-16 17:18:55,161 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:55,163 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:18:55,164 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:18:55,171 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:55,275 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:18:55,397 - INFO - Progress: 196 samples processed in 0:13:36.778480\n",
      "Processing samples:  98%|█████████▊| 197/200 [13:36<00:08,  2.76s/it]2024-11-16 17:18:55,777 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:55,778 - INFO - Retrying request to /chat/completions in 0.394009 seconds\n",
      "2024-11-16 17:18:56,429 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:56,430 - INFO - Retrying request to /chat/completions in 0.790822 seconds\n",
      "2024-11-16 17:18:57,490 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:57,975 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:57,976 - INFO - Retrying request to /chat/completions in 0.443851 seconds\n",
      "2024-11-16 17:18:58,712 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:58,713 - INFO - Retrying request to /chat/completions in 0.855920 seconds\n",
      "2024-11-16 17:18:58,738 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:58,739 - INFO - Retrying request to /chat/completions in 0.469786 seconds\n",
      "2024-11-16 17:18:59,337 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:18:59,491 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:59,492 - INFO - Retrying request to /chat/completions in 0.853495 seconds\n",
      "2024-11-16 17:18:59,823 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:18:59,824 - WARNING - Attempt 1 failed: Error code: 429 - {'error': {'code': None, 'message': 'Rate limit exceeded', 'param': None, 'type': 'rate_limit_exceeded'}}\n",
      "2024-11-16 17:19:00,600 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2024-11-16 17:19:00,917 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:00,920 - INFO - LLMCall function forward\n",
      "2024-11-16 17:19:00,920 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:19:02,755 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:02,757 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:19:02,758 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:19:03,894 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:03,896 - INFO - LLMCall function forward\n",
      "2024-11-16 17:19:03,897 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:19:03,928 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:03,930 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:19:03,930 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:19:03,936 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:19:04,013 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:19:04,086 - INFO - Progress: 200 samples processed in 0:13:45.468224\n",
      "Processing samples:  99%|█████████▉| 198/200 [13:45<00:09,  4.54s/it]2024-11-16 17:19:06,143 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:06,145 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:19:06,146 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:19:06,945 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:06,947 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:19:06,947 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:19:06,954 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:19:07,078 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:19:07,183 - INFO - Progress: 198 samples processed in 0:13:48.565054\n",
      "Processing samples: 100%|█████████▉| 199/200 [13:48<00:04,  4.11s/it]2024-11-16 17:19:08,978 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:10,421 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:10,423 - INFO - LLMCall function forward\n",
      "2024-11-16 17:19:10,423 - INFO - _backward_through_llm prompt\n",
      "2024-11-16 17:19:11,988 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:11,990 - INFO - _backward_through_llm gradient\n",
      "2024-11-16 17:19:11,990 - INFO - TextualGradientDescent prompt for update\n",
      "2024-11-16 17:19:13,212 - INFO - HTTP Request: POST https://api.sambanova.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-16 17:19:13,214 - INFO - TextualGradientDescent optimizer response\n",
      "2024-11-16 17:19:13,214 - INFO - TextualGradientDescent updated text\n",
      "2024-11-16 17:19:13,220 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:19:13,290 - INFO - Using default tokenizer.\n",
      "2024-11-16 17:19:13,360 - INFO - Progress: 199 samples processed in 0:13:54.741498\n",
      "Processing samples: 100%|██████████| 200/200 [13:54<00:00,  4.17s/it]\n",
      "2024-11-16 17:19:13,375 - INFO - Results saved to 'final_results.json'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from textgrad.engine.local_model_openai_api import ChatExternalClient\n",
    "import textgrad as tg\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import itertools\n",
    "from threading import Lock\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import yake\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ensure NLTK punkt is downloaded\n",
    "def ensure_punkt():\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        logging.info(\"Downloading NLTK 'punkt' tokenizer...\")\n",
    "        nltk.download('punkt')\n",
    "        \n",
    "\n",
    "ensure_punkt()\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Rate limiting constants\n",
    "RATE_LIMIT = 30  # requests per minute per API key\n",
    "DELAY_BETWEEN_REQUESTS = 60 / RATE_LIMIT  # seconds between requests\n",
    "BATCH_SIZE = 25  # Slightly less than rate limit to account for overhead\n",
    "API_KEYS = [\n",
    "    \"2405b5bd-7cf3-4536-b632-5bb16db66f34\",\n",
    "    \"1bac03be-d6ac-4b73-9aea-9ae7bd81a793\",\n",
    "    \"9718ad80-530a-4719-a677-05f06d144eff\",\n",
    "    \"7aad8b10-3d4e-4be0-b96e-5de389ae85b3\"\n",
    "]\n",
    "api_key_cycle = itertools.cycle(API_KEYS)\n",
    "key_lock = Lock()\n",
    "\n",
    "def calculate_metrics(reference, candidate):\n",
    "    metrics = {}\n",
    "    \n",
    "    # Ensure NLTK punkt is available\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        logging.info(\"Downloading NLTK 'punkt' tokenizer within thread...\")\n",
    "        nltk.download('punkt')\n",
    "    \n",
    "    # Content Similarity using TF-IDF Cosine Similarity\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform([reference, candidate])\n",
    "        metrics['content_similarity'] = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"TF-IDF Cosine Similarity failed: {e}\")\n",
    "        metrics['content_similarity'] = 0\n",
    "\n",
    "    # Word Overlap\n",
    "    try:\n",
    "        ref_words = set(reference.lower().split())\n",
    "        cand_words = set(candidate.lower().split())\n",
    "        metrics['word_overlap'] = len(ref_words.intersection(cand_words)) / len(ref_words) if len(ref_words) > 0 else 0\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Word Overlap calculation failed: {e}\")\n",
    "        metrics['word_overlap'] = 0\n",
    "\n",
    "    # BLEU Score\n",
    "    try:\n",
    "        smoothie = SmoothingFunction().method4\n",
    "        reference_tokens = nltk.word_tokenize(reference.lower())\n",
    "        candidate_tokens = nltk.word_tokenize(candidate.lower())\n",
    "        metrics['bleu_score'] = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothie)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"BLEU Score calculation failed: {e}\")\n",
    "        metrics['bleu_score'] = 0\n",
    "\n",
    "    # ROUGE Scores\n",
    "    try:\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        rouge_scores = scorer.score(reference, candidate)\n",
    "        metrics['rouge1'] = rouge_scores['rouge1'].fmeasure\n",
    "        metrics['rouge2'] = rouge_scores['rouge2'].fmeasure\n",
    "        metrics['rougeL'] = rouge_scores['rougeL'].fmeasure\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ROUGE Scores calculation failed: {e}\")\n",
    "        metrics['rouge1'] = metrics['rouge2'] = metrics['rougeL'] = 0\n",
    "\n",
    "    # Keyword Matching\n",
    "    try:\n",
    "        kw_extractor = yake.KeywordExtractor()\n",
    "        ref_keywords = {kw[0] for kw in kw_extractor.extract_keywords(reference)}\n",
    "        cand_keywords = {kw[0] for kw in kw_extractor.extract_keywords(candidate)}\n",
    "        metrics['keyword_overlap'] = len(ref_keywords.intersection(cand_keywords)) / len(ref_keywords) if len(ref_keywords) > 0 else 0\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Keyword Matching calculation failed: {e}\")\n",
    "        metrics['keyword_overlap'] = 0\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def get_gpt_response(client, prompt, retry_count=3):\n",
    "    \"\"\"Get GPT response with rate limiting and character limit\"\"\"\n",
    "    system_prompt = \"\"\"You are a medical expert assistant. Provide accurate, clear, and well-structured medical advice.\n",
    "Focus on: accuracy, clear explanation, practical advice, and professional yet accessible language.\n",
    "Please limit your response to a maximum of 1500 characters.\"\"\"\n",
    "\n",
    "    for attempt in range(retry_count):\n",
    "        try:\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)  # Rate limiting\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"Meta-Llama-3.1-70B-Instruct\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=400  # Approximate to 1500 characters\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < retry_count - 1:\n",
    "                time.sleep(5)  # Wait longer between retries\n",
    "    logging.error(\"All retry attempts failed for GPT response.\")\n",
    "    return \"\"\n",
    "\n",
    "def estimate_completion_time(total_samples):\n",
    "    \"\"\"Calculate estimated completion time based on rate limits\"\"\"\n",
    "    # Each sample needs 2 API calls (GPT and TextGrad)\n",
    "    total_requests = total_samples * 2\n",
    "\n",
    "    # Calculate total minutes needed\n",
    "    total_minutes = total_requests / RATE_LIMIT\n",
    "\n",
    "    # Add 20% buffer for overhead and potential retries\n",
    "    total_minutes *= 1.2\n",
    "\n",
    "    return timedelta(minutes=total_minutes)\n",
    "\n",
    "def limit_response(response, limit=1500):\n",
    "    \"\"\"Truncate the response to the specified character limit\"\"\"\n",
    "    return response[:limit] if len(response) > limit else response\n",
    "\n",
    "def process_sample(row, start_time):\n",
    "    batch_results = {}\n",
    "    try:\n",
    "        with key_lock:\n",
    "            api_key = next(api_key_cycle)\n",
    "        client = OpenAI(base_url=\"https://api.sambanova.ai/v1\", api_key=api_key)\n",
    "        engine = ChatExternalClient(client=client, model_string='Meta-Llama-3.1-70B-Instruct')\n",
    "        tg.set_backward_engine(engine, override=True)\n",
    "\n",
    "        loss_system_prompt = tg.Variable(\n",
    "        \"\"\"Evaluate the medical response based on the following criteria:\n",
    "        - Accuracy: Ensure all information is factually correct and evidence-based.\n",
    "        - Clarity: The response should be clear, concise, and easy to understand.\n",
    "        - Completeness: Address all aspects of the medical query comprehensively.\n",
    "        - Practicality: Provide actionable and practical advice that can be implemented.\n",
    "        - Professionalism: Maintain a professional tone and uphold medical ethical standards.\n",
    "        - Relevance: Ensure all information provided is directly related to the query.\n",
    "        - Consistency: Maintain consistency in terminology and presentation throughout the response.\n",
    "        - No Questions: The response should not contain any questions or prompts for additional information.\n",
    "       \"\"\",\n",
    "            requires_grad=False,\n",
    "            role_description=\"medical evaluation system\"\n",
    "        )\n",
    "        # Get GPT response\n",
    "        gpt_response = get_gpt_response(client, row['input'])\n",
    "\n",
    "        if not gpt_response:\n",
    "            logging.error(f\"GPT response for index {row.name} is empty.\")\n",
    "            return {}\n",
    "\n",
    "        # TextGrad optimization (includes its own API call)\n",
    "        solution = tg.Variable(row['output'], requires_grad=True, role_description=\"medical response\")\n",
    "        loss_fn = tg.TextLoss(loss_system_prompt)\n",
    "        optimizer = tg.TGD([solution])\n",
    "        loss = loss_fn(solution)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        textgrad_response = solution.value\n",
    "\n",
    "        # Limit TextGrad response to 1500 characters\n",
    "        textgrad_response = limit_response(textgrad_response, 1500)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics_gpt = calculate_metrics(row['output'], gpt_response)\n",
    "        metrics_textgrad = calculate_metrics(row['output'], textgrad_response)\n",
    "\n",
    "        batch_results = {\n",
    "            'index': row.name,\n",
    "            'responses': {\n",
    "                'gpt': gpt_response,\n",
    "                'textgrad': textgrad_response\n",
    "            },\n",
    "            'metrics': {\n",
    "                'gpt': metrics_gpt,\n",
    "                'textgrad': metrics_textgrad\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Show time progress\n",
    "        elapsed = datetime.now() - start_time\n",
    "        samples_processed = row.name + 1\n",
    "        logging.info(f\"Progress: {samples_processed} samples processed in {elapsed}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing index {row.name}: {e}\")\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "def main():\n",
    "    print(\"Loading dataset...\")\n",
    "    try:\n",
    "        df = pd.read_parquet(r'/workspaces/codespaces-jupyter/data/train-00000-of-00001-5e7cb295b9cff0bf.parquet').head(200)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load dataset: {e}\")\n",
    "        return\n",
    "\n",
    "    total_samples = len(df)\n",
    "\n",
    "    # Calculate and display time estimate\n",
    "    estimated_duration = estimate_completion_time(total_samples)\n",
    "    start_time = datetime.now()\n",
    "    estimated_completion = start_time + estimated_duration\n",
    "\n",
    "    print(f\"\\nProcessing {total_samples} samples:\")\n",
    "    print(f\"Start time: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Estimated completion: {estimated_completion.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Estimated duration: {estimated_duration}\")\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            future_to_index = {executor.submit(process_sample, row, start_time): idx for idx, row in df.iterrows()}\n",
    "            for future in tqdm(as_completed(future_to_index), total=total_samples, desc=\"Processing samples\"):\n",
    "                result = future.result()\n",
    "                if result and result.get('metrics'):\n",
    "                    all_results.append(result)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess interrupted by user. Saving partial results...\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # Save final results\n",
    "        final_results = {\n",
    "            'metadata': {\n",
    "                'total_samples_processed': len(all_results),\n",
    "                'start_time': start_time.isoformat(),\n",
    "                'end_time': datetime.now().isoformat(),\n",
    "                'actual_duration': str(datetime.now() - start_time),\n",
    "            },\n",
    "            'results': all_results\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open('final_results.json', 'w') as f:\n",
    "                json.dump(final_results, f, indent=2)\n",
    "            logging.info(\"Results saved to 'final_results.json'\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save results: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
